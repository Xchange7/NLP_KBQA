{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e11a5701-cea3-4c38-8f84-27f84aba242d",
      "metadata": {
        "id": "e11a5701-cea3-4c38-8f84-27f84aba242d"
      },
      "source": [
        "## KQAPro Baselines Pipeline - SPARQL Setup\n",
        "\n",
        "This Jupyter Notebook is designed to set up the pipeline for the [KQAPro Baselines - SPARQL](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL) project. It provides steps for downloading the necessary datasets, organizing files, and preparing the environment to run the SPARQL-based code.\n",
        "\n",
        "Ensure that all dependencies are installed and the required tools are available in your system before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd6584a",
      "metadata": {
        "id": "2fd6584a"
      },
      "source": [
        "> To Run it on **Colab**:\n",
        ">\n",
        "> 1. First, **upload** and open this jupyter **notebook** file  \n",
        ">\n",
        "> 2. Second, clone the related [github repository](https://github.com/Xchange7/NLP_KBQA) by executing the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "57ab1a4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ab1a4f",
        "outputId": "54e44671-ffc5-4581-87bd-05b07eacc737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP_KBQA'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 139 (delta 74), reused 103 (delta 41), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (139/139), 74.58 KiB | 771.00 KiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Xchange7/NLP_KBQA.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2b8b50",
      "metadata": {
        "id": "fd2b8b50"
      },
      "source": [
        "> 3. change the directory to `sp-based/`\n",
        ">\n",
        ">     Use `%cd` rather than `!cd` !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b553752",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b553752",
        "outputId": "b98a40d5-0a00-496f-c959-55094f772d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/NLP_KBQA/sp-based\n"
          ]
        }
      ],
      "source": [
        "%cd NLP_KBQA/sp-based/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "uwIdx7jpK12U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwIdx7jpK12U",
        "outputId": "192924c9-23b8-44b5-c29b-93a0639e53ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/NLP_KBQA/sp-based\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8516955",
      "metadata": {
        "id": "d8516955"
      },
      "source": [
        "> 4. Now continue the following cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a",
      "metadata": {
        "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a"
      },
      "source": [
        "### Download Datasets\n",
        "\n",
        "The following 4 jupyter cells will do the followings:\n",
        "\n",
        "- Download datasets `train.json`, `val.json` and `test.json` from [https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1](https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1)\n",
        "- Download datasets `kb.json` from [https://huggingface.co/datasets/drt/kqa_pro](https://huggingface.co/datasets/drt/kqa_pro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
        "outputId": "8048b280-0a90-4298-b702-b35fe5596dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-12 19:59:02--  https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\n",
            "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
            "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/7470d729-403c-4ebc-b5a1-bbe3d3a8fe71/KQAPro.IID.zip [following]\n",
            "--2024-12-12 19:59:03--  https://cloud.tsinghua.edu.cn/seafhttp/files/7470d729-403c-4ebc-b5a1-bbe3d3a8fe71/KQAPro.IID.zip\n",
            "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24786704 (24M) [application/zip]\n",
            "Saving to: ‘datasets.zip’\n",
            "\n",
            "datasets.zip        100%[===================>]  23.64M  6.91MB/s    in 3.7s    \n",
            "\n",
            "2024-12-12 19:59:07 (6.43 MB/s) - ‘datasets.zip’ saved [24786704/24786704]\n",
            "\n",
            "Archive:  datasets.zip\n",
            "   creating: datasets/KQAPro.IID/\n",
            "  inflating: datasets/KQAPro.IID/kb.json  \n",
            "  inflating: datasets/KQAPro.IID/README.md  \n",
            "  inflating: datasets/KQAPro.IID/train.json  \n",
            "  inflating: datasets/KQAPro.IID/test.json  \n",
            "  inflating: datasets/KQAPro.IID/val.json  \n"
          ]
        }
      ],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets.zip \"https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\" \\\n",
        "&& unzip -o datasets.zip -d datasets \\\n",
        "&& mv datasets/KQAPro.IID/* datasets/ \\\n",
        "&& rm -r datasets/KQAPro.IID \\\n",
        "&& rm datasets.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
        "outputId": "08c7327a-c7fd-4866-de6f-846fc8eb77f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mBlindGRU\u001b[0m/  evaluate.py    README.md        \u001b[01;34mSPARQL\u001b[0m/                \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mdatasets\u001b[0m/  json2jsonl.py  run_BlindGRU.sh  SPARQL_pipeline.ipynb\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
        "outputId": "97cc5e78-da72-4c41-d201-ffb58259683f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-12 19:59:22--  https://huggingface.co/datasets/drt/kqa_pro/resolve/main/kb.json?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/c0/a4/c0a4536356b7a43fa2d5f4ca0859ea436a28848a2a32e920357a4480a00d4aa7/04da7408320c5cb7023c44372cce32846d56d369d8865d2e61a18c3956661a7c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27kb.json%3B+filename%3D%22kb.json%22%3B&response-content-type=application%2Fjson&Expires=1734292762&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDI5Mjc2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jMC9hNC9jMGE0NTM2MzU2YjdhNDNmYTJkNWY0Y2EwODU5ZWE0MzZhMjg4NDhhMmEzMmU5MjAzNTdhNDQ4MGEwMGQ0YWE3LzA0ZGE3NDA4MzIwYzVjYjcwMjNjNDQzNzJjY2UzMjg0NmQ1NmQzNjlkODg2NWQyZTYxYTE4YzM5NTY2NjFhN2M%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Whh8heUUNzrmys7DkmFxhJ5JR61wosSJcEVBoy4d4eT%7Ed3-C5VetH9uC%7EYXP9imD-53-kuzQt3%7EqZ27AuM0Zpf8mAI-pBABNOcSc3O31978gj2Ki3dmgU-vrsl5y2QuffNge5c1R63dTjh7RX2QYhJJCD2aX14jdrKq7kGXyClaPDRTVB-bS1hMCfqZ6X%7EQEnAUzvzf3zSqmxNEhyemuepI24qdczobpzXe7kubYHuIVtOheOL0AcviMODX2fz44feSGCq6HjTRVvGvrCHSMQnrs5wFb0mpIBHVIyCU5gBdfk4PRtksh20lQFkHAqzl3noado1DvLFJksT8E42Nq7g__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-12 19:59:22--  https://cdn-lfs.hf.co/repos/c0/a4/c0a4536356b7a43fa2d5f4ca0859ea436a28848a2a32e920357a4480a00d4aa7/04da7408320c5cb7023c44372cce32846d56d369d8865d2e61a18c3956661a7c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27kb.json%3B+filename%3D%22kb.json%22%3B&response-content-type=application%2Fjson&Expires=1734292762&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDI5Mjc2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jMC9hNC9jMGE0NTM2MzU2YjdhNDNmYTJkNWY0Y2EwODU5ZWE0MzZhMjg4NDhhMmEzMmU5MjAzNTdhNDQ4MGEwMGQ0YWE3LzA0ZGE3NDA4MzIwYzVjYjcwMjNjNDQzNzJjY2UzMjg0NmQ1NmQzNjlkODg2NWQyZTYxYTE4YzM5NTY2NjFhN2M%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Whh8heUUNzrmys7DkmFxhJ5JR61wosSJcEVBoy4d4eT%7Ed3-C5VetH9uC%7EYXP9imD-53-kuzQt3%7EqZ27AuM0Zpf8mAI-pBABNOcSc3O31978gj2Ki3dmgU-vrsl5y2QuffNge5c1R63dTjh7RX2QYhJJCD2aX14jdrKq7kGXyClaPDRTVB-bS1hMCfqZ6X%7EQEnAUzvzf3zSqmxNEhyemuepI24qdczobpzXe7kubYHuIVtOheOL0AcviMODX2fz44feSGCq6HjTRVvGvrCHSMQnrs5wFb0mpIBHVIyCU5gBdfk4PRtksh20lQFkHAqzl3noado1DvLFJksT8E42Nq7g__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.239.50.101, 18.239.50.30, 18.239.50.53, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.239.50.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79341787 (76M) [application/json]\n",
            "Saving to: ‘datasets/kb.json’\n",
            "\n",
            "datasets/kb.json    100%[===================>]  75.67M   210MB/s    in 0.4s    \n",
            "\n",
            "2024-12-12 19:59:23 (210 MB/s) - ‘datasets/kb.json’ saved [79341787/79341787]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets/kb.json \"https://huggingface.co/datasets/drt/kqa_pro/resolve/main/kb.json?download=true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
        "outputId": "b68e9ac8-1b67-40e1-ad57-7fa2c0d35b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kb.json  README.md  test.json  train.json  val.json\n"
          ]
        }
      ],
      "source": [
        "%ls ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d223c74d-d46d-4799-84f9-202a070f3816",
      "metadata": {
        "id": "d223c74d-d46d-4799-84f9-202a070f3816"
      },
      "source": [
        "### Configure rdflib package\n",
        "\n",
        "Follow the instructions in [https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
        "outputId": "64fb61f2-c151-498b-8d44-f71da2abe8bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate<1.0.0,>=0.7.2 (from rdflib)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.2.0)\n",
            "Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/562.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.7.2 rdflib-7.1.1\n"
          ]
        }
      ],
      "source": [
        "%pip install rdflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
        "outputId": "71902267-e30b-4e9c-a4fb-9e4134d90ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base_dir: /usr/local/lib/python3.10/dist-packages/rdflib\n",
            "\n",
            "There are 2 files to change in total.\n",
            "File1: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/sparql/parser.py\n",
            "File2: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py\n",
            "\n",
            "First, edit file1, replace the line with codes:\n",
            "`if i + 1 < l and (not isinstance(terms[i + 1], str) or terms[i + 1] not in \".,;\"):`\n",
            "which is just below the line `# is this bnode the subject of more triplets?`\n",
            "\n",
            "Second, edit file2, replace `use_plain=True` with `use_plain=False`\n",
            "\n",
            "For more detailed information, check https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements\n"
          ]
        }
      ],
      "source": [
        "import rdflib\n",
        "import os\n",
        "\n",
        "\"\"\" Follow the instructions of the output below: \"\"\"\n",
        "\n",
        "base_dir = os.path.dirname(rdflib.__file__)\n",
        "print(f\"base_dir: {base_dir}\")\n",
        "\n",
        "file1 = os.path.join(base_dir, \"plugins/sparql/parser.py\")\n",
        "file2 = os.path.join(base_dir, \"plugins/serializers/turtle.py\")\n",
        "\n",
        "\"\"\"What you need TODO:\"\"\"\n",
        "print(\"\\nThere are 2 files to change in total.\")\n",
        "print(f\"File1: {file1}\")\n",
        "print(f\"File2: {file2}\")\n",
        "\n",
        "print(f\"\"\"\n",
        "First, edit file1, replace the line with codes:\n",
        "`if i + 1 < l and (not isinstance(terms[i + 1], str) or terms[i + 1] not in \".,;\"):`\n",
        "which is just below the line `# is this bnode the subject of more triplets?`\n",
        "\"\"\", end=\"\")\n",
        "\n",
        "print(f\"\"\"\n",
        "Second, edit file2, replace `use_plain=True` with `use_plain=False`\n",
        "\"\"\")\n",
        "\n",
        "print(\"For more detailed information, check https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wHZc03euLHNH",
      "metadata": {
        "id": "wHZc03euLHNH"
      },
      "source": [
        "Now edit file1 and file2.\n",
        "\n",
        "> For Colab users, the file paths could be:  \n",
        ">\n",
        "> File1: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/sparql/parser.py  \n",
        ">\n",
        "> File2: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py  \n",
        ">\n",
        "> Simply click the file links to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ad52a04-9360-4203-847f-b5221e1eabfc",
      "metadata": {
        "id": "5ad52a04-9360-4203-847f-b5221e1eabfc"
      },
      "source": [
        "### Configure SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
        "outputId": "3c291eca-cd3a-4d25-86ec-c7e66d2234f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SPARQLWrapper==1.8.4\n",
            "  Downloading SPARQLWrapper-1.8.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: rdflib>=4.0 in /usr/local/lib/python3.10/dist-packages (from SPARQLWrapper==1.8.4) (7.1.1)\n",
            "Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from rdflib>=4.0->SPARQLWrapper==1.8.4) (0.7.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=4.0->SPARQLWrapper==1.8.4) (3.2.0)\n",
            "Downloading SPARQLWrapper-1.8.4-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-1.8.4\n"
          ]
        }
      ],
      "source": [
        "%pip install SPARQLWrapper==1.8.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d518e511-c41b-4042-80a9-44967f5e515b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d518e511-c41b-4042-80a9-44967f5e515b",
        "outputId": "66e1ba7b-ce00-4c27-dcfc-aae7d9205c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: keepalive\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip show keepalive  # Make sure `keepalive` NOT installed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9",
      "metadata": {
        "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9"
      },
      "source": [
        "### Virtuoso Configuration\n",
        "\n",
        "> *Needed for validation and evaluation (Executing SPARQL query to local Virtuoso database)*\n",
        "\n",
        "- The virtuoso backend will start up a web service, we can import our kb into it and then execute SPARQL queries by network requests.\n",
        "- **Purpose of Virtuoso**: The primary purpose of this configuration is to install and set up the Virtuoso backend service on an Ubuntu system, enabling the import of a **knowledge base (KB)** and facilitating access and operations on the data through the **SPARQL query interface**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd",
      "metadata": {
        "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd"
      },
      "source": [
        "Follow the steps in [https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#how-to-install-virtuoso-backend](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#how-to-install-virtuoso-backend) or [SPARQL/virtuoso-commands.md](./SPARQL/virtuoso-commands.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b96db1cf-2994-4b60-a454-5ae07852351a",
      "metadata": {
        "id": "b96db1cf-2994-4b60-a454-5ae07852351a"
      },
      "source": [
        "### Preprocess the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6ae20098-be27-484c-b327-6d189b5a199c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae20098-be27-484c-b327-6d189b5a199c",
        "outputId": "276835bf-c4aa-48c8-9614-fac18e0fabc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
        "outputId": "646e73df-5545-4df8-f6ee-b4748d2c68eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build kb vocabulary\n",
            "Load questions\n",
            "Build question vocabulary\n",
            "Dump vocab to processed_data/vocab.json\n",
            "word_token_to_idx:48554\n",
            "sparql_token_to_idx:45693\n",
            "answer_token_to_idx:81629\n",
            "Encode train set\n",
            "100% 94376/94376 [00:15<00:00, 6143.36it/s]\n",
            "shape of questions, sparqls, choices, answers:\n",
            "(94376, 85)\n",
            "(94376, 103)\n",
            "(94376, 10)\n",
            "(94376,)\n",
            "Encode val set\n",
            "100% 11797/11797 [00:01<00:00, 7585.62it/s]\n",
            "shape of questions, sparqls, choices, answers:\n",
            "(11797, 61)\n",
            "(11797, 100)\n",
            "(11797, 10)\n",
            "(11797,)\n",
            "Encode test set\n",
            "100% 11797/11797 [00:01<00:00, 7885.38it/s]\n",
            "shape of questions, sparqls, choices, answers:\n",
            "(11797, 51)\n",
            "(0,)\n",
            "(11797, 10)\n",
            "(0,)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m SPARQL.preprocess --input_dir ./datasets --output_dir processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
        "outputId": "f3960ef9-baec-4dc0-c2c4-d4b7ab2bda1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets:\n",
            "kb.json  README.md  test.json  train.json  val.json\n",
            "\n",
            "processed_data:\n",
            "test.pt  train.pt  val.pt  vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls datasets processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a",
      "metadata": {
        "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a"
      },
      "outputs": [],
      "source": [
        "!cp ./datasets/kb.json processed_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1511c61b-a00a-4264-afce-a9b947171e9a",
      "metadata": {
        "id": "1511c61b-a00a-4264-afce-a9b947171e9a"
      },
      "source": [
        "### Train\n",
        "\n",
        "**BUG here!!!**:  \n",
        "\n",
        "There is a bug when the command below is executed with GPU, which can be fixed by editing the file:   \n",
        "`....../dist-packages/torch/nn/utils/rnn.py`  \n",
        "In Colab, the file path is:  \n",
        "`/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py: line 338`\n",
        "\n",
        "Add `lengths = lengths.cpu()` before the line `data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c109e198-cf8d-434c-9f43-a618f3279326",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c109e198-cf8d-434c-9f43-a618f3279326",
        "outputId": "819f0b46-fbc8-432d-d028-562fb090edce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-12-12 20:12:21,733 INFO     input_dir:processed_data/\n",
            "2024-12-12 20:12:21,733 INFO     save_dir:checkpoints/\n",
            "2024-12-12 20:12:21,733 INFO     lr:0.001\n",
            "2024-12-12 20:12:21,733 INFO     weight_decay:1e-05\n",
            "2024-12-12 20:12:21,733 INFO     num_epoch:10\n",
            "2024-12-12 20:12:21,733 INFO     batch_size:64\n",
            "2024-12-12 20:12:21,734 INFO     seed:666\n",
            "2024-12-12 20:12:21,734 INFO     dim_word:300\n",
            "2024-12-12 20:12:21,734 INFO     dim_hidden:1024\n",
            "2024-12-12 20:12:21,734 INFO     max_dec_len:100\n",
            "2024-12-12 20:12:21,734 INFO     virtuoso_enabled:True\n",
            "2024-12-12 20:12:21,755 INFO     Create train_loader and val_loader.........\n",
            "#vocab of word/sparql/answer: 48554/45693/81629\n",
            "2024-12-12 20:12:28,276 INFO     Create model.........\n",
            "2024-12-12 20:12:29,597 INFO     SPARQLParser(\n",
            "  (word_embeddings): Embedding(48554, 300)\n",
            "  (word_dropout): Dropout(p=0.3, inplace=False)\n",
            "  (question_encoder): GRU(\n",
            "    (encoder): GRU(300, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (sparql_embeddings): Embedding(45693, 300)\n",
            "  (decoder): GRU(\n",
            "    (encoder): GRU(300, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (sparql_classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=45693, bias=True)\n",
            "  )\n",
            "  (att_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
            ")\n",
            "2024-12-12 20:12:30,541 INFO     Start training........\n",
            "2024-12-12 20:12:43,382 INFO     epoch: 0  batch: 14/1475  loss: 6.7515 (6.5407)  lr: 0.001000\n",
            "2024-12-12 20:12:54,900 INFO     epoch: 0  batch: 28/1475  loss: 1.2494 (3.8346)  lr: 0.001000\n"
          ]
        }
      ],
      "source": [
        "# without GPU\n",
        "# !python3 -m SPARQL.train --input_dir processed_data/ --save_dir checkpoints/ --virtuoso_enabled False --num_epoch 1 \n",
        "\n",
        "# with GPU\n",
        "# Run on Colab: --virtuoso_enabled False, there is no Virtuoso on Colab, no validating when training\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.train --input_dir processed_data/ --save_dir checkpoints/ --virtuoso_enabled False --num_epoch 10 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8df0ce",
      "metadata": {},
      "source": [
        "### Test\n",
        "\n",
        "On Colab: unable to run the test command without configuration of Virtuoso Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4161ab87-26ba-4a71-863d-bfab745daea7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4161ab87-26ba-4a71-863d-bfab745daea7",
        "outputId": "380f210b-6c4c-42df-c2c4-ca5277d36110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load test data\n",
            "load model\n",
            "100% 93/93 [00:59<00:00,  1.56it/s]\n"
          ]
        }
      ],
      "source": [
        "# without GPU\n",
        "# !python -m SPARQL.predict --input_dir processed_data/ --save_dir checkpoints/\n",
        "\n",
        "# with GPU\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.predict --input_dir processed_data/ --save_dir checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UQIsX1vfgLQL",
      "metadata": {
        "id": "UQIsX1vfgLQL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
