{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e11a5701-cea3-4c38-8f84-27f84aba242d",
      "metadata": {
        "id": "e11a5701-cea3-4c38-8f84-27f84aba242d"
      },
      "source": [
        "## KQAPro Baselines Pipeline - SPARQL Setup\n",
        "\n",
        "This Jupyter Notebook is designed to set up the pipeline for the [KQAPro Baselines - SPARQL](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL) project. It provides steps for downloading the necessary datasets, organizing files, and preparing the environment to run the SPARQL-based code.\n",
        "\n",
        "Ensure that all dependencies are installed and the required tools are available in your system before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd6584a",
      "metadata": {
        "id": "2fd6584a"
      },
      "source": [
        "> To Run it on **Colab**:\n",
        ">\n",
        "> 1. First, **upload** and open this jupyter **notebook** file  \n",
        ">\n",
        "> 2. Second, clone the related [github repository](https://github.com/Xchange7/NLP_KBQA) by executing the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ab1a4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ab1a4f",
        "outputId": "0091b257-3c59-42d0-d361-bf6ea26b55e1"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Xchange7/NLP_KBQA.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2b8b50",
      "metadata": {
        "id": "fd2b8b50"
      },
      "source": [
        "> 3. change the directory to `sp-based/`\n",
        ">\n",
        ">     Use `%cd` rather than `!cd` !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b553752",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b553752",
        "outputId": "96c08224-faf4-45a0-c689-386e88828d60"
      },
      "outputs": [],
      "source": [
        "%cd NLP_KBQA/sp-based/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uwIdx7jpK12U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwIdx7jpK12U",
        "outputId": "70dc1f14-b763-432b-c58e-10439f9a4722"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8516955",
      "metadata": {
        "id": "d8516955"
      },
      "source": [
        "> 4. Now continue the following cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a",
      "metadata": {
        "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a"
      },
      "source": [
        "### Download Datasets\n",
        "\n",
        "The following 4 jupyter cells will do the followings:\n",
        "\n",
        "- Download datasets `train.json`, `val.json` and `test.json` from [https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1](https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1)\n",
        "- Download datasets `kb.json` from [https://huggingface.co/datasets/drt/kqa_pro](https://huggingface.co/datasets/drt/kqa_pro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
        "outputId": "40976c6f-dc44-4adf-c4b2-b40cc018c8d4"
      },
      "outputs": [],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets.zip \"https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\" \\\n",
        "&& unzip -o datasets.zip -d datasets \\\n",
        "&& mv datasets/KQAPro.IID/* datasets/ \\\n",
        "&& rm -r datasets/KQAPro.IID \\\n",
        "&& rm datasets.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
        "outputId": "3293e5bf-20bc-42c5-8b02-63365a6c90e8"
      },
      "outputs": [],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
        "outputId": "4d25b8e5-3b81-4073-9792-9ee77fb4d71b"
      },
      "outputs": [],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets/kb.json \"https://huggingface.co/datasets/drt/kqa_pro/resolve/main/kb.json?download=true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
        "outputId": "d6bbb66e-5931-4141-9393-6072cece28b1"
      },
      "outputs": [],
      "source": [
        "%ls ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5696ed62",
      "metadata": {
        "id": "5696ed62"
      },
      "source": [
        "### Modify the datasets\n",
        "\n",
        "- Current structures of `train.json`, `val.json`:\n",
        "  ```json\n",
        "  {\n",
        "    \"question\": \"\",   // !!! input of the model\n",
        "    \"choices\": [],  // ignore this field\n",
        "    \"program\": [],  // ignore this field\n",
        "    \"sparql\": \"\",   // !!! output of the model\n",
        "    \"answer\": \"\"  // ignore this field\n",
        "  }\n",
        "  ```\n",
        "\n",
        "- Current structure of `test.json`:\n",
        "  ```json\n",
        "  {\n",
        "    \"question\": \"\",   // !!! input of the model\n",
        "    \"answer\": \"\"  // ignore this field\n",
        "  }  // PROBLEM: no `sparql` field\n",
        "  ```\n",
        "\n",
        "- Current `test.json` file has no `sparql` field, so we split the `val.json` into two parts, taking the last **5000** pieces of samples as new test set, and others as evaluation set.\n",
        "- At the same time, we also restructure the json format in all `train.json`, `val.json`, `test.json` files with proper **indentation**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "681a2d78",
      "metadata": {
        "id": "681a2d78"
      },
      "outputs": [],
      "source": [
        "!rm ./datasets/test.json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c70d960d",
      "metadata": {
        "id": "c70d960d"
      },
      "source": [
        "Currently, all data are stored in **a single line** in each file, which is not human-readable. We will reformat the data to make it more readable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534a5ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "534a5ba5",
        "outputId": "2e587fa5-9e4f-4b7e-a261-4e75597ca3fb"
      },
      "outputs": [],
      "source": [
        "!wc -l ./datasets/*.json  # calculate the number of lines in each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44f9c4d",
      "metadata": {
        "id": "b44f9c4d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "with open('./datasets/val.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "if len(data) != 11797:  # original number of samples in `val.json`\n",
        "    # the file has been restructured with proper indentation\n",
        "    raise Exception('The file `val.json` has been split into `val.json` and `test.json` already!\\nNo need to run this script again.')\n",
        "\n",
        "# fetch the last 5000 samples as test data\n",
        "test_data = data[-5000:]\n",
        "remaining_data = data[:-5000]\n",
        "\n",
        "with open('./datasets/test.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(test_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "with open('./datasets/val.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(remaining_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# at the same time, restructure `train.json` with proper indentation\n",
        "with open('./datasets/train.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "with open('./datasets/train.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print('Successfully split `val.json` into `val.json` and `test.json`, and restructured all files with indentation.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec89a24a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec89a24a",
        "outputId": "4e2edef8-44ef-4e35-c3a8-450021a75e2f"
      },
      "outputs": [],
      "source": [
        "!wc -l ./datasets/*.json  # calculate the number of lines in each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f277af7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f277af7c",
        "outputId": "18661404-8902-4b39-c984-454ad327d55b"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: convert `train.json`, `val.json`, and `test.json` to `jsonl` format\n",
        "\n",
        "!python json2jsonl.py --mode default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cba9303",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cba9303",
        "outputId": "eefc1cf6-e44a-4a6f-a368-ef84a82aca89"
      },
      "outputs": [],
      "source": [
        "!wc -l ./datasets/*.jsonl  # calculate the number of lines in each file, which represents the number of samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d223c74d-d46d-4799-84f9-202a070f3816",
      "metadata": {
        "id": "d223c74d-d46d-4799-84f9-202a070f3816"
      },
      "source": [
        "### Configure rdflib package\n",
        "\n",
        "Follow the instructions in [https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
        "outputId": "14342293-dd99-4bbc-b019-298fef7d1914"
      },
      "outputs": [],
      "source": [
        "%pip install rdflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
        "outputId": "befaa13f-031a-49a7-c756-4a62c6fd8ebe"
      },
      "outputs": [],
      "source": [
        "import rdflib\n",
        "import os\n",
        "\n",
        "\"\"\" Follow the instructions of the output below: \"\"\"\n",
        "\n",
        "base_dir = os.path.dirname(rdflib.__file__)\n",
        "print(f\"base_dir: {base_dir}\")\n",
        "\n",
        "file1 = os.path.join(base_dir, \"plugins/sparql/parser.py\")\n",
        "file2 = os.path.join(base_dir, \"plugins/serializers/turtle.py\")\n",
        "\n",
        "\"\"\"What you need TODO:\"\"\"\n",
        "print(\"\\nThere are 2 files to change in total.\")\n",
        "print(f\"File1: {file1}\")\n",
        "print(f\"File2: {file2}\")\n",
        "\n",
        "print(f\"\"\"\n",
        "First, edit file1, replace the line with codes:\n",
        "`if i + 1 < l and (not isinstance(terms[i + 1], str) or terms[i + 1] not in \".,;\"):`\n",
        "which is just below the line `# is this bnode the subject of more triplets?`\n",
        "\"\"\", end=\"\")\n",
        "\n",
        "print(f\"\"\"\n",
        "Second, edit file2, replace `use_plain=True` with `use_plain=False`\n",
        "\"\"\")\n",
        "\n",
        "print(\"For more detailed information, check https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wHZc03euLHNH",
      "metadata": {
        "id": "wHZc03euLHNH"
      },
      "source": [
        "Now edit file1 and file2.\n",
        "\n",
        "> For Colab users, the file paths could be:  \n",
        ">\n",
        "> File1: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/sparql/parser.py  \n",
        ">\n",
        "> File2: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py  \n",
        ">\n",
        "> Simply click the file links to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ad52a04-9360-4203-847f-b5221e1eabfc",
      "metadata": {
        "id": "5ad52a04-9360-4203-847f-b5221e1eabfc"
      },
      "source": [
        "### Configure SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
        "outputId": "82592945-6853-48db-fba5-10f40473d967"
      },
      "outputs": [],
      "source": [
        "%pip install SPARQLWrapper==1.8.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d518e511-c41b-4042-80a9-44967f5e515b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d518e511-c41b-4042-80a9-44967f5e515b",
        "outputId": "1856ed68-da24-4322-8f6c-7036f32dba0c"
      },
      "outputs": [],
      "source": [
        "%pip show keepalive  # Make sure `keepalive` NOT installed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9",
      "metadata": {
        "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9"
      },
      "source": [
        "### Virtuoso Configuration\n",
        "\n",
        "> *Needed for validation and evaluation (Executing SPARQL query to local Virtuoso database)*\n",
        "\n",
        "- The virtuoso backend will start up a web service, we can import our kb into it and then execute SPARQL queries by network requests.\n",
        "- **Purpose of Virtuoso**: The primary purpose of this configuration is to install and set up the Virtuoso backend service on an Ubuntu system, enabling the import of a **knowledge base (KB)** and facilitating access and operations on the data through the **SPARQL query interface**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd",
      "metadata": {
        "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd"
      },
      "source": [
        "Follow the steps in [https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#how-to-install-virtuoso-backend](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#how-to-install-virtuoso-backend) or [SPARQL/virtuoso-commands.md](./SPARQL/virtuoso-commands.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eaff19f",
      "metadata": {
        "id": "8eaff19f"
      },
      "source": [
        "### Loguru Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb20ca86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb20ca86",
        "outputId": "7e1149ef-d42a-4a46-d3e8-87805d01b63a"
      },
      "outputs": [],
      "source": [
        "%pip install loguru"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b96db1cf-2994-4b60-a454-5ae07852351a",
      "metadata": {
        "id": "b96db1cf-2994-4b60-a454-5ae07852351a"
      },
      "source": [
        "### Preprocess the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae20098-be27-484c-b327-6d189b5a199c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae20098-be27-484c-b327-6d189b5a199c",
        "outputId": "d138fc3d-a605-4711-c7e9-644e916f074d"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
        "outputId": "193e2d33-b9d9-4846-8bdf-8e0caf5cf89a"
      },
      "outputs": [],
      "source": [
        "!python3 -m SPARQL.preprocess --input_dir ./datasets --output_dir processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
        "outputId": "7ec8d1fb-e7d4-4208-e53b-bd5e93a2fd85"
      },
      "outputs": [],
      "source": [
        "%ls datasets processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a",
      "metadata": {
        "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a"
      },
      "outputs": [],
      "source": [
        "!cp ./datasets/kb.json processed_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1511c61b-a00a-4264-afce-a9b947171e9a",
      "metadata": {
        "id": "1511c61b-a00a-4264-afce-a9b947171e9a"
      },
      "source": [
        "### Train\n",
        "\n",
        "**BUG here!!!**:  \n",
        "\n",
        "There is a bug when the command below is executed with GPU, which can be fixed by editing the file:   \n",
        "`....../dist-packages/torch/nn/utils/rnn.py`  \n",
        "In Colab, the file path is:  \n",
        "`/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py: line 338`\n",
        "\n",
        "Add `lengths = lengths.cpu()` before the line `data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c109e198-cf8d-434c-9f43-a618f3279326",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c109e198-cf8d-434c-9f43-a618f3279326",
        "outputId": "72e0f35b-d7bb-4e07-aec8-6db45b897308"
      },
      "outputs": [],
      "source": [
        "# without GPU\n",
        "# !python3 -m SPARQL.train --input_dir processed_data/ --save_dir checkpoints/ --virtuoso_enabled False --num_epoch 1\n",
        "\n",
        "# with GPU\n",
        "# Run on Colab: --virtuoso_enabled False, there is no Virtuoso on Colab, no validating when training\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.train --input_dir processed_data/ --save_dir checkpoints/ --virtuoso_enabled False --num_epoch 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8df0ce",
      "metadata": {
        "id": "0c8df0ce"
      },
      "source": [
        "### Test\n",
        "\n",
        "On Colab: unable to run the test command without configuration of Virtuoso Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4161ab87-26ba-4a71-863d-bfab745daea7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4161ab87-26ba-4a71-863d-bfab745daea7",
        "outputId": "380f210b-6c4c-42df-c2c4-ca5277d36110"
      },
      "outputs": [],
      "source": [
        "# without GPU\n",
        "# !python -m SPARQL.predict --input_dir processed_data/ --save_dir checkpoints/\n",
        "\n",
        "# with GPU\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.predict --input_dir processed_data/ --save_dir checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UQIsX1vfgLQL",
      "metadata": {
        "id": "UQIsX1vfgLQL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
