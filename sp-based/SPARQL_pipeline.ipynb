{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e11a5701-cea3-4c38-8f84-27f84aba242d",
      "metadata": {
        "id": "e11a5701-cea3-4c38-8f84-27f84aba242d"
      },
      "source": [
        "## KQAPro Baselines Pipeline - SPARQL Setup\n",
        "\n",
        "This Jupyter Notebook is designed to set up the pipeline for the [KQAPro Baselines - SPARQL](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL) project. It provides steps for downloading the necessary datasets, organizing files, and preparing the environment to run the SPARQL-based code.\n",
        "\n",
        "Ensure that all dependencies are installed and the required tools are available in your system before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd6584a",
      "metadata": {
        "id": "2fd6584a"
      },
      "source": [
        "> To Run it on **Colab**:\n",
        ">\n",
        "> 1. First, **upload** and open this jupyter **notebook** file  \n",
        ">\n",
        "> 2. Second, clone the related [github repository](https://github.com/Xchange7/NLP_KBQA) by executing the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "57ab1a4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ab1a4f",
        "outputId": "5ab227c5-7bd2-4e24-9e3c-d7a598f19565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_KBQA'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 53 (delta 16), reused 45 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (53/53), 45.69 KiB | 698.00 KiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Xchange7/NLP_KBQA.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2b8b50",
      "metadata": {
        "id": "fd2b8b50"
      },
      "source": [
        "> 3. change the directory to `sp-based/`\n",
        ">\n",
        ">     Use `%cd` rather than `!cd` !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b553752",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b553752",
        "outputId": "73acaae6-67cf-43d8-b54f-94a132f0c33c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_KBQA/sp-based\n"
          ]
        }
      ],
      "source": [
        "%cd NLP_KBQA/sp-based/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwIdx7jpK12U",
        "outputId": "05eeedc4-8d8e-42c6-a97e-afab1ac60abb"
      },
      "id": "uwIdx7jpK12U",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_KBQA/sp-based\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8516955",
      "metadata": {
        "id": "d8516955"
      },
      "source": [
        "> 4. Now continue the following cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a",
      "metadata": {
        "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a"
      },
      "source": [
        "### Download Datasets\n",
        "\n",
        "The following 4 jupyter cells will do the followings:\n",
        "\n",
        "- Download datasets `train.json`, `val.json` and `test.json` from [https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1](https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1)\n",
        "- Download datasets `kb.json` from [https://huggingface.co/datasets/drt/kqa_pro](https://huggingface.co/datasets/drt/kqa_pro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
        "outputId": "0cf1eadb-38ab-4e13-cb29-beeacb50403e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 20:54:05--  https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\n",
            "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
            "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/1d68fc4b-6206-4e66-925b-9754092a3055/KQAPro.IID.zip [following]\n",
            "--2024-12-09 20:54:07--  https://cloud.tsinghua.edu.cn/seafhttp/files/1d68fc4b-6206-4e66-925b-9754092a3055/KQAPro.IID.zip\n",
            "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24786704 (24M) [application/zip]\n",
            "Saving to: ‘datasets.zip’\n",
            "\n",
            "datasets.zip        100%[===================>]  23.64M  7.48MB/s    in 3.7s    \n",
            "\n",
            "2024-12-09 20:54:10 (6.37 MB/s) - ‘datasets.zip’ saved [24786704/24786704]\n",
            "\n",
            "Archive:  datasets.zip\n",
            "   creating: datasets/KQAPro.IID/\n",
            "  inflating: datasets/KQAPro.IID/kb.json  \n",
            "  inflating: datasets/KQAPro.IID/README.md  \n",
            "  inflating: datasets/KQAPro.IID/train.json  \n",
            "  inflating: datasets/KQAPro.IID/test.json  \n",
            "  inflating: datasets/KQAPro.IID/val.json  \n"
          ]
        }
      ],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets.zip \"https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\" \\\n",
        "&& unzip -o datasets.zip -d datasets \\\n",
        "&& mv datasets/KQAPro.IID/* datasets/ \\\n",
        "&& rm -r datasets/KQAPro.IID \\\n",
        "&& rm datasets.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
        "outputId": "2dd6c24f-fa86-4bdf-c45c-b62062aa9102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdatasets\u001b[0m/  evaluate.py  README.md  \u001b[01;34mSPARQL\u001b[0m/  SPARQL_pipeline.ipynb  \u001b[01;34mutils\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
        "outputId": "a847c975-31bf-4d45-e57b-781ccfc6ba6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 20:54:17--  https://huggingface.co/datasets/drt/kqa_pro/resolve/main/kb.json?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.17, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/c0/a4/c0a4536356b7a43fa2d5f4ca0859ea436a28848a2a32e920357a4480a00d4aa7/04da7408320c5cb7023c44372cce32846d56d369d8865d2e61a18c3956661a7c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27kb.json%3B+filename%3D%22kb.json%22%3B&response-content-type=application%2Fjson&Expires=1734036862&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDAzNjg2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jMC9hNC9jMGE0NTM2MzU2YjdhNDNmYTJkNWY0Y2EwODU5ZWE0MzZhMjg4NDhhMmEzMmU5MjAzNTdhNDQ4MGEwMGQ0YWE3LzA0ZGE3NDA4MzIwYzVjYjcwMjNjNDQzNzJjY2UzMjg0NmQ1NmQzNjlkODg2NWQyZTYxYTE4YzM5NTY2NjFhN2M%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=gTdm6y%7EzwiSxbXPGP78FUwApLZu82Rxnz4X21O-2ZyV2syfOIai0vhI4QUPkS0b3P8HmOOmfUHW3Jw6MGyuoGvH4oIxMLN5w8DhLPqBVpsFrdzSJwxNSiYhr0Qju-xeJSuhFEwSyUIWS6lLzaq64f97zmt0257YKiZI5aC4tIebo3LrLy6hn1J4C73kffnHxFEanfONI591Lgi-EzK7JfthWhZQjAtwM2RThUZuIaGWs%7Eymie%7EIFG7f5ikJykPQKDSQVvPz5cbN8j%7EjXg%7E9XdRKz78JZ2IQKd%7Eyzx7jvOeUd6sDfSTpYiPksYrm%7E5zKDbuz-5NK7FxZgWbW-VRMp9w__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-09 20:54:22--  https://cdn-lfs.hf.co/repos/c0/a4/c0a4536356b7a43fa2d5f4ca0859ea436a28848a2a32e920357a4480a00d4aa7/04da7408320c5cb7023c44372cce32846d56d369d8865d2e61a18c3956661a7c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27kb.json%3B+filename%3D%22kb.json%22%3B&response-content-type=application%2Fjson&Expires=1734036862&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDAzNjg2Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jMC9hNC9jMGE0NTM2MzU2YjdhNDNmYTJkNWY0Y2EwODU5ZWE0MzZhMjg4NDhhMmEzMmU5MjAzNTdhNDQ4MGEwMGQ0YWE3LzA0ZGE3NDA4MzIwYzVjYjcwMjNjNDQzNzJjY2UzMjg0NmQ1NmQzNjlkODg2NWQyZTYxYTE4YzM5NTY2NjFhN2M%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=gTdm6y%7EzwiSxbXPGP78FUwApLZu82Rxnz4X21O-2ZyV2syfOIai0vhI4QUPkS0b3P8HmOOmfUHW3Jw6MGyuoGvH4oIxMLN5w8DhLPqBVpsFrdzSJwxNSiYhr0Qju-xeJSuhFEwSyUIWS6lLzaq64f97zmt0257YKiZI5aC4tIebo3LrLy6hn1J4C73kffnHxFEanfONI591Lgi-EzK7JfthWhZQjAtwM2RThUZuIaGWs%7Eymie%7EIFG7f5ikJykPQKDSQVvPz5cbN8j%7EjXg%7E9XdRKz78JZ2IQKd%7Eyzx7jvOeUd6sDfSTpYiPksYrm%7E5zKDbuz-5NK7FxZgWbW-VRMp9w__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.99, 3.168.132.25, 3.168.132.51, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79341787 (76M) [application/json]\n",
            "Saving to: ‘datasets/kb.json’\n",
            "\n",
            "datasets/kb.json    100%[===================>]  75.67M  70.1MB/s    in 1.1s    \n",
            "\n",
            "2024-12-09 20:54:23 (70.1 MB/s) - ‘datasets/kb.json’ saved [79341787/79341787]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets/kb.json \"https://huggingface.co/datasets/drt/kqa_pro/resolve/main/kb.json?download=true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
        "outputId": "41bae20a-a074-4841-90c5-9aa56f0b68ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kb.json  README.md  test.json  train.json  val.json\n"
          ]
        }
      ],
      "source": [
        "%ls ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d223c74d-d46d-4799-84f9-202a070f3816",
      "metadata": {
        "id": "d223c74d-d46d-4799-84f9-202a070f3816"
      },
      "source": [
        "### Configure rdflib package\n",
        "\n",
        "Follow the instructions in [https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
        "outputId": "b9bd6555-c3c1-450f-da95-ee6c91f02991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate<1.0.0,>=0.7.2 (from rdflib)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.2.0)\n",
            "Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.7.2 rdflib-7.1.1\n"
          ]
        }
      ],
      "source": [
        "%pip install rdflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
        "outputId": "3876eab2-f088-44b7-fb4a-a129e6033d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_dir: /usr/local/lib/python3.10/dist-packages/rdflib\n",
            "\n",
            "There are 2 files to change in total.\n",
            "File1: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/sparql/parser.py\n",
            "File2: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py\n",
            "\n",
            "First, edit file1, replace the line with codes:\n",
            "`if i + 1 < l and (not isinstance(terms[i + 1], str) or terms[i + 1] not in \".,;\"):`\n",
            "which is just below the line `# is this bnode the subject of more triplets?`\n",
            "\n",
            "Second, edit file2, replace `use_plain=True` with `use_plain=False`\n",
            "\n",
            "For more detailed information, check https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements\n"
          ]
        }
      ],
      "source": [
        "import rdflib\n",
        "import os\n",
        "\n",
        "\"\"\" Follow the instructions of the output below: \"\"\"\n",
        "\n",
        "base_dir = os.path.dirname(rdflib.__file__)\n",
        "print(f\"base_dir: {base_dir}\")\n",
        "\n",
        "file1 = os.path.join(base_dir, \"plugins/sparql/parser.py\")\n",
        "file2 = os.path.join(base_dir, \"plugins/serializers/turtle.py\")\n",
        "\n",
        "\"\"\"What you need TODO:\"\"\"\n",
        "print(\"\\nThere are 2 files to change in total.\")\n",
        "print(f\"File1: {file1}\")\n",
        "print(f\"File2: {file2}\")\n",
        "\n",
        "print(f\"\"\"\n",
        "First, edit file1, replace the line with codes:\n",
        "`if i + 1 < l and (not isinstance(terms[i + 1], str) or terms[i + 1] not in \".,;\"):`\n",
        "which is just below the line `# is this bnode the subject of more triplets?`\n",
        "\"\"\", end=\"\")\n",
        "\n",
        "print(f\"\"\"\n",
        "Second, edit file2, replace `use_plain=True` with `use_plain=False`\n",
        "\"\"\")\n",
        "\n",
        "print(\"For more detailed information, check https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now edit file1 and file2.\n",
        "\n",
        "> For Colab users, the file paths could be:  \n",
        ">\n",
        "> File1: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/sparql/parser.py  \n",
        ">\n",
        "> File2: /usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py  \n",
        ">\n",
        "> Simply click the file links to edit"
      ],
      "metadata": {
        "id": "wHZc03euLHNH"
      },
      "id": "wHZc03euLHNH"
    },
    {
      "cell_type": "markdown",
      "id": "5ad52a04-9360-4203-847f-b5221e1eabfc",
      "metadata": {
        "id": "5ad52a04-9360-4203-847f-b5221e1eabfc"
      },
      "source": [
        "### Configure SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
        "outputId": "1d9e131b-e129-4da2-edb4-fe514836f61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SPARQLWrapper==1.8.4\n",
            "  Downloading SPARQLWrapper-1.8.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: rdflib>=4.0 in /usr/local/lib/python3.10/dist-packages (from SPARQLWrapper==1.8.4) (7.1.1)\n",
            "Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from rdflib>=4.0->SPARQLWrapper==1.8.4) (0.7.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=4.0->SPARQLWrapper==1.8.4) (3.2.0)\n",
            "Downloading SPARQLWrapper-1.8.4-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-1.8.4\n"
          ]
        }
      ],
      "source": [
        "%pip install SPARQLWrapper==1.8.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d518e511-c41b-4042-80a9-44967f5e515b",
      "metadata": {
        "id": "d518e511-c41b-4042-80a9-44967f5e515b",
        "outputId": "df3558b4-38e8-4e59-fef3-56dc233178a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: keepalive\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip show keepalive  # Make sure `keepalive` NOT installed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9",
      "metadata": {
        "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9"
      },
      "source": [
        "### Virtuoso Configuration (Optional)\n",
        "\n",
        "> *Not needed if we don't continue to process the SPARQL statements by querying the Knowledge Base.*\n",
        "\n",
        "- The virtuoso backend will start up a web service, we can import our kb into it and then execute SPARQL queries by network requests.\n",
        "- **Purpose of Virtuoso**: The primary purpose of this configuration is to install and set up the Virtuoso backend service on an Ubuntu system, enabling the import of a **knowledge base (KB)** and facilitating access and operations on the data through the **SPARQL query interface**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd",
      "metadata": {
        "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd"
      },
      "source": [
        "Follow the steps in [https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#how-to-install-virtuoso-backend](https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#how-to-install-virtuoso-backend)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b96db1cf-2994-4b60-a454-5ae07852351a",
      "metadata": {
        "id": "b96db1cf-2994-4b60-a454-5ae07852351a"
      },
      "source": [
        "### Preprocess the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6ae20098-be27-484c-b327-6d189b5a199c",
      "metadata": {
        "id": "6ae20098-be27-484c-b327-6d189b5a199c",
        "outputId": "07344fd8-8c40-42e9-a670-a4cdbe3554db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
      "metadata": {
        "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
        "outputId": "0a9d74ea-4862-469d-e636-75a8e23bf2d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build kb vocabulary\n",
            "Load questions\n",
            "Build question vocabulary\n",
            "Dump vocab to processed_data/vocab.json\n",
            "word_token_to_idx:48554\n",
            "sparql_token_to_idx:45693\n",
            "answer_token_to_idx:81629\n",
            "Encode train set\n",
            "100% 94376/94376 [00:14<00:00, 6343.88it/s]\n",
            "shape of questions, sparqls, choices, answers:\n",
            "(94376, 85)\n",
            "(94376, 103)\n",
            "(94376, 10)\n",
            "(94376,)\n",
            "Encode val set\n",
            "100% 11797/11797 [00:01<00:00, 7530.37it/s]\n",
            "shape of questions, sparqls, choices, answers:\n",
            "(11797, 61)\n",
            "(11797, 100)\n",
            "(11797, 10)\n",
            "(11797,)\n",
            "Encode test set\n",
            "100% 11797/11797 [00:01<00:00, 8713.01it/s]\n",
            "shape of questions, sparqls, choices, answers:\n",
            "(11797, 51)\n",
            "(0,)\n",
            "(11797, 10)\n",
            "(0,)\n"
          ]
        }
      ],
      "source": [
        "!python -m SPARQL.preprocess --input_dir ./datasets --output_dir processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
      "metadata": {
        "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
        "outputId": "2313c2e4-23d7-4793-85d2-297230e5cf4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets:\n",
            "kb.json  README.md  test.json  train.json  val.json\n",
            "\n",
            "processed_data:\n",
            "test.pt  train.pt  val.pt  vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls datasets processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a",
      "metadata": {
        "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a"
      },
      "outputs": [],
      "source": [
        "!cp ./datasets/kb.json processed_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1511c61b-a00a-4264-afce-a9b947171e9a",
      "metadata": {
        "id": "1511c61b-a00a-4264-afce-a9b947171e9a"
      },
      "source": [
        "### Train\n",
        "\n",
        "**BUG here!!!**:  \n",
        "\n",
        "There is a bug when the command below is executed with GPU, which can be fixed by editing the file:   \n",
        "`....../dist-packages/torch/nn/utils/rnn.py`  \n",
        "In Colab, the file path is:  \n",
        "`/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py`\n",
        "\n",
        "Add `lengths = lengths.cpu()` before the line `data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c109e198-cf8d-434c-9f43-a618f3279326",
      "metadata": {
        "id": "c109e198-cf8d-434c-9f43-a618f3279326",
        "outputId": "6e019d01-e8dc-44a3-8f29-26f5562f8fc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-09 21:04:10,290 INFO     input_dir:processed_data/\n",
            "2024-12-09 21:04:10,290 INFO     save_dir:checkpoints/\n",
            "2024-12-09 21:04:10,290 INFO     lr:0.001\n",
            "2024-12-09 21:04:10,290 INFO     weight_decay:1e-05\n",
            "2024-12-09 21:04:10,290 INFO     num_epoch:5\n",
            "2024-12-09 21:04:10,290 INFO     batch_size:64\n",
            "2024-12-09 21:04:10,290 INFO     seed:666\n",
            "2024-12-09 21:04:10,290 INFO     dim_word:300\n",
            "2024-12-09 21:04:10,290 INFO     dim_hidden:1024\n",
            "2024-12-09 21:04:10,290 INFO     max_dec_len:100\n",
            "2024-12-09 21:04:10,352 INFO     Create train_loader and val_loader.........\n",
            "#vocab of word/sparql/answer: 48554/45693/81629\n",
            "2024-12-09 21:04:15,716 INFO     Create model.........\n",
            "2024-12-09 21:04:17,188 INFO     SPARQLParser(\n",
            "  (word_embeddings): Embedding(48554, 300)\n",
            "  (word_dropout): Dropout(p=0.3, inplace=False)\n",
            "  (question_encoder): GRU(\n",
            "    (encoder): GRU(300, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (sparql_embeddings): Embedding(45693, 300)\n",
            "  (decoder): GRU(\n",
            "    (encoder): GRU(300, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (sparql_classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=45693, bias=True)\n",
            "  )\n",
            "  (att_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
            ")\n",
            "2024-12-09 21:04:20,452 INFO     Start training........\n",
            "2024-12-09 21:04:34,251 INFO     progress: 0.009  loss: 6.7515 (6.5407)  lr: 0.001000\n",
            "2024-12-09 21:04:45,883 INFO     progress: 0.019  loss: 1.2494 (3.8346)  lr: 0.001000\n",
            "2024-12-09 21:04:57,676 INFO     progress: 0.028  loss: 0.9343 (2.8733)  lr: 0.001000\n",
            "2024-12-09 21:05:09,600 INFO     progress: 0.038  loss: 0.7876 (2.3437)  lr: 0.001000\n",
            "2024-12-09 21:05:21,709 INFO     progress: 0.047  loss: 0.7166 (2.0174)  lr: 0.001000\n",
            "2024-12-09 21:05:33,794 INFO     progress: 0.057  loss: 0.6707 (1.7921)  lr: 0.001000\n",
            "2024-12-09 21:05:46,069 INFO     progress: 0.066  loss: 0.6248 (1.6269)  lr: 0.001000\n",
            "2024-12-09 21:05:58,477 INFO     progress: 0.076  loss: 0.6161 (1.5004)  lr: 0.001000\n",
            "2024-12-09 21:06:11,214 INFO     progress: 0.085  loss: 0.5840 (1.3984)  lr: 0.001000\n",
            "2024-12-09 21:06:24,164 INFO     progress: 0.095  loss: 0.5776 (1.3168)  lr: 0.001000\n",
            "2024-12-09 21:06:37,424 INFO     progress: 0.104  loss: 0.5520 (1.2475)  lr: 0.001000\n",
            "2024-12-09 21:06:50,910 INFO     progress: 0.114  loss: 0.5520 (1.1901)  lr: 0.001000\n"
          ]
        }
      ],
      "source": [
        "# !python -m SPARQL.train --input_dir processed_data/ --save_dir checkpoints/ --num_epoch 5  # without GPU\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.train --input_dir processed_data/ --save_dir checkpoints/ --num_epoch 5  # with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4161ab87-26ba-4a71-863d-bfab745daea7",
      "metadata": {
        "id": "4161ab87-26ba-4a71-863d-bfab745daea7"
      },
      "outputs": [],
      "source": [
        "# !python -m SPARQL.predict --input_dir processed_data/ --save_dir checkpoints/  # without GPU\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.predict --input_dir processed_data/ --save_dir checkpoints/  # with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e995810c-2f86-48bf-9324-b39d41632280",
      "metadata": {
        "id": "e995810c-2f86-48bf-9324-b39d41632280"
      },
      "outputs": [],
      "source": [
        "# keep colab running\n",
        "while True:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofejH23_PnME"
      },
      "id": "ofejH23_PnME",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}