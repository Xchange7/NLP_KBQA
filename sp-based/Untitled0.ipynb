{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1"
      ],
      "metadata": {
        "id": "7DJgjjPmfVxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c09221-6a53-490e-8a26-2b84407b31c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-08 10:02:58--  https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\n",
            "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
            "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/589f16d9-eee3-47ef-b9bd-d5bb99faa157/KQAPro.IID.zip [following]\n",
            "--2024-12-08 10:02:59--  https://cloud.tsinghua.edu.cn/seafhttp/files/589f16d9-eee3-47ef-b9bd-d5bb99faa157/KQAPro.IID.zip\n",
            "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24786704 (24M) [application/zip]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>]  23.64M  7.50MB/s    in 3.6s    \n",
            "\n",
            "2024-12-08 10:03:03 (6.58 MB/s) - ‘index.html?dl=1’ saved [24786704/24786704]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv index.html\\?dl\\=1 KQAPro.IID.zip"
      ],
      "metadata": {
        "id": "HhzBvnOiubwR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip KQAPro.IID.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcP8hjK2ukIG",
        "outputId": "b35d6fe4-8679-42a1-9800-215173cf2efc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  KQAPro.IID.zip\n",
            "   creating: KQAPro.IID/\n",
            "  inflating: KQAPro.IID/kb.json      \n",
            "  inflating: KQAPro.IID/README.md    \n",
            "  inflating: KQAPro.IID/train.json   \n",
            "  inflating: KQAPro.IID/test.json    \n",
            "  inflating: KQAPro.IID/val.json     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv KQAPro.IID/ KQAPro_Baselines/datasets"
      ],
      "metadata": {
        "id": "M7EKgd9uuuvP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shijx12/KQAPro_Baselines.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCIObOJXuN6I",
        "outputId": "552a0c5e-eb8a-4103-ca00-e7492d93eead"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KQAPro_Baselines'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 431 (delta 19), reused 12 (delta 5), pack-reused 389 (from 1)\u001b[K\n",
            "Receiving objects: 100% (431/431), 908.86 KiB | 2.95 MiB/s, done.\n",
            "Resolving deltas: 100% (269/269), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install kopl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvpu7gYyuS2n",
        "outputId": "18bdc3e5-7ef0-409d-f99d-b3e0f3b40f3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kopl\n",
            "  Downloading KoPL-0.0.5-py3-none-any.whl.metadata (588 bytes)\n",
            "Downloading KoPL-0.0.5-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: kopl\n",
            "Successfully installed kopl-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd KQAPro_Baselines"
      ],
      "metadata": {
        "id": "0jsZqHjsu5QA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O ./pretrained/bart-base_model.zip https://cloud.tsinghua.edu.cn/f/3b59ec6c43034cfc8841/?dl=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y22IFVvfxaw0",
        "outputId": "439b6909-0e3c-4c9b-c2d3-54bd1e5afa03"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-08 10:21:20--  https://cloud.tsinghua.edu.cn/f/3b59ec6c43034cfc8841/?dl=1\n",
            "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
            "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/21ff78f1-bead-44e9-a5b4-d80e3c0b97c2/bart-base.zip [following]\n",
            "--2024-12-08 10:21:21--  https://cloud.tsinghua.edu.cn/seafhttp/files/21ff78f1-bead-44e9-a5b4-d80e3c0b97c2/bart-base.zip\n",
            "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 329582587 (314M) [application/zip]\n",
            "Saving to: ‘./pretrained/bart-base_model.zip’\n",
            "\n",
            "./pretrained/bart-b 100%[===================>] 314.31M  11.3MB/s    in 31s     \n",
            "\n",
            "2024-12-08 10:21:53 (10.2 MB/s) - ‘./pretrained/bart-base_model.zip’ saved [329582587/329582587]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./pretrained/bart-base_model.zip -d ./pretrained"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHgaD5VLy_10",
        "outputId": "368b59c5-af6b-4e4c-90e7-e8b78ab5a5a0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./pretrained/bart-base_model.zip\n",
            "   creating: ./pretrained/bart-base/\n",
            "  inflating: ./pretrained/bart-base/vocab.url.json  \n",
            "  inflating: ./pretrained/bart-base/config.url.json  \n",
            "  inflating: ./pretrained/bart-base/config.json  \n",
            "  inflating: ./pretrained/bart-base/merges.txt  \n",
            "  inflating: ./pretrained/bart-base/merges.url.json  \n",
            "  inflating: ./pretrained/bart-base/pytorch_model.url.bin  \n",
            "  inflating: ./pretrained/bart-base/pytorch_model.bin  \n",
            "  inflating: ./pretrained/bart-base/vocab.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m Bart_Program.preprocess --input_dir ./dataset --output_dir processed_files --model_name_or_path ./pretrained/bart-base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zocfj2wRu_ve",
        "outputId": "aee7c986-8a25-4ded-8f19-0ab2b7b66336"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-08 10:25:08.486778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-08 10:25:08.506227: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-08 10:25:08.512096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-08 10:25:08.526019: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-08 10:25:09.735255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "GroupViT models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version.Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "Build kb vocabulary\n",
            "Load questions\n",
            "Dump vocab to processed_files/vocab.json\n",
            "answer_token_to_idx:81629\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading file tokenizer.json\n",
            "loading configuration file ./pretrained/bart-base/config.json\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"./pretrained/bart-base\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"transformers_version\": \"4.46.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Encode train set\n",
            "100% 94376/94376 [00:00<00:00, 351404.75it/s]\n",
            "tokenizing\n",
            "tokenize ended.\n",
            "dict_keys(['input_ids', 'attention_mask'])\n",
            "[0, 32251, 1139, 34, 10, 3842, 2688, 9, 204, 45121, 406, 34916, 3416, 1360, 8, 34, 41, 8192, 7961, 5135, 9, 6178, 398, 35534, 116, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "<s>Which town has a TOID of 4000000074573917 and has an OS grid reference of SP8778?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "<s>FindAll  <func>  FilterStr  <arg>  official website  <arg>  http://www.thesiege.com/  <func>  FilterConcept  <arg>  visual artwork  <func>  QueryAttrQualifier  <arg>  publication date  <arg>  1999-01-21  <arg>  place of publication</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "171\n",
            "100% 94376/94376 [00:00<00:00, 152722.69it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "shape of input_ids of questions, attention_mask of questions, input_ids of sparqls, choices and answers:\n",
            "(94376, 171)\n",
            "(94376, 171)\n",
            "(94376, 171)\n",
            "(94376, 10)\n",
            "(94376,)\n",
            "Encode val set\n",
            "100% 11797/11797 [00:00<00:00, 219927.66it/s]\n",
            "tokenizing\n",
            "tokenize ended.\n",
            "dict_keys(['input_ids', 'attention_mask'])\n",
            "[0, 12375, 21, 5, 4588, 1924, 77, 3801, 4, 3635, 8538, 300, 5, 3536, 3683, 13, 2700, 8123, 6, 27738, 196, 14828, 5785, 116, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "<s>Who was the prize winner when Mrs. Miniver got the Academy Award for Best Writing, Adapted Screenplay?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "<s>Find  <arg>  Luzerne County  <func>  Find  <arg>  Wilkes-Barre  <func>  QueryRelation</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "132\n",
            "100% 11797/11797 [00:00<00:00, 56725.92it/s]\n",
            "shape of input_ids of questions, attention_mask of questions, input_ids of sparqls, choices and answers:\n",
            "(11797, 132)\n",
            "(11797, 132)\n",
            "(11797, 132)\n",
            "(11797, 10)\n",
            "(11797,)\n",
            "Encode test set\n",
            "100% 11797/11797 [00:00<00:00, 2007147.67it/s]\n",
            "tokenizing\n",
            "tokenize ended.\n",
            "dict_keys(['input_ids', 'attention_mask'])\n",
            "[0, 32251, 1569, 16, 10941, 6, 2393, 261, 35, 18089, 50, 11114, 9, 5, 7599, 35, 20, 43459, 9, 5, 1378, 14109, 116, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "<s>Which movie is shorter, Tron: Legacy or Pirates of the Caribbean: The Curse of the Black Pearl?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "<s>Which person directed the war film Up?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "87\n",
            "100% 11797/11797 [00:00<00:00, 317162.50it/s]\n",
            "shape of input_ids of questions, attention_mask of questions, input_ids of sparqls, choices and answers:\n",
            "(11797, 87)\n",
            "(11797, 87)\n",
            "(0,)\n",
            "(11797, 10)\n",
            "(0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./dataset/kb.json ./processed_files/"
      ],
      "metadata": {
        "id": "YmbnbEhSzpq7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m Bart_Program.train --input_dir ./processed_files/ --output_dir checkpoints \\\n",
        " --save_dir logs --model_name_or_path ./pretrained/bart-base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my7dG71gv5_T",
        "outputId": "8fbfbfac-6297-47b3-df80-051651fe7da2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-08 10:29:58.191592: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-08 10:29:58.210824: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-08 10:29:58.216644: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-08 10:29:58.230614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Exception ignored in: <function _get_module_lock.<locals>.cb at 0x1291cc4991b0>\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 198, in cb\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/KQAPro_Baselines/Bart_Program/train.py\", line 11, in <module>\n",
            "    from transformers import BartConfig, BartForConditionalGeneration, BartTokenizer\n",
            "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\", line 1767, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\", line 1766, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\", line 1778, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 44, in <module>\n",
            "    from ...modeling_utils import PreTrainedModel\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 48, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/loss/loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/loss/loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py\", line 50, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 9, in <module>\n",
            "    from tensorflow.python.autograph.impl.api import tf_convert # line: 493\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 25, in <module>\n",
            "    from tensorflow.python.autograph import operators\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/__init__.py\", line 36, in <module>\n",
            "    from tensorflow.python.autograph.operators.conditional_expressions import if_exp\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/conditional_expressions.py\", line 18, in <module>\n",
            "    from tensorflow.python.autograph.operators import control_flow\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 64, in <module>\n",
            "    from tensorflow.python.autograph.operators import py_builtins\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/py_builtins.py\", line 32, in <module>\n",
            "    from tensorflow.python.ops import gen_string_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_string_ops.py\", line 2450, in <module>\n",
            "    UnicodeEncode = tf_export(\"raw_ops.UnicodeEncode\")(_ops.to_raw_op(unicode_encode))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 5978, in to_raw_op\n",
            "    return kwarg_only(f)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_export.py\", line 367, in kwarg_only\n",
            "    f_argspec = tf_inspect.getfullargspec(f)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_inspect.py\", line 284, in getfullargspec\n",
            "    return _getfullargspec(target)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1277, in getfullargspec\n",
            "    sig = _signature_from_callable(func,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2463, in _signature_from_callable\n",
            "    return _signature_from_function(sigcls, obj,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2370, in _signature_from_function\n",
            "    return cls(parameters,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2969, in __init__\n",
            "    params = OrderedDict((param.name, param) for param in parameters)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2969, in <genexpr>\n",
            "    params = OrderedDict((param.name, param) for param in parameters)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrxXUMAJ0bFX",
        "outputId": "5e3a1d44-c5dc-49ae-adae-a967a5bc5588"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec  8 10:30:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python -m Bart_Program.train --input_dir ./processed_files/ --output_dir checkpoints \\\n",
        " --save_dir logs --model_name_or_path ./pretrained/bart-base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgL4df3K0b9v",
        "outputId": "773ec07e-e100-4246-eebe-79a626fd494e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-08 10:30:54.215669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-08 10:30:54.235530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-08 10:30:54.241312: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-08 10:30:54.255846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-08 10:30:55.397579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-12-08 10:30:56,708 INFO     input_dir:./processed_files/\n",
            "2024-12-08 10:30:56,708 INFO     output_dir:checkpoints\n",
            "2024-12-08 10:30:56,708 INFO     save_dir:logs\n",
            "2024-12-08 10:30:56,708 INFO     model_name_or_path:./pretrained/bart-base\n",
            "2024-12-08 10:30:56,708 INFO     ckpt:None\n",
            "2024-12-08 10:30:56,708 INFO     weight_decay:1e-05\n",
            "2024-12-08 10:30:56,709 INFO     batch_size:16\n",
            "2024-12-08 10:30:56,709 INFO     seed:666\n",
            "2024-12-08 10:30:56,709 INFO     learning_rate:3e-05\n",
            "2024-12-08 10:30:56,709 INFO     num_train_epochs:25\n",
            "2024-12-08 10:30:56,709 INFO     save_steps:448\n",
            "2024-12-08 10:30:56,709 INFO     logging_steps:448\n",
            "2024-12-08 10:30:56,709 INFO     warmup_proportion:0.1\n",
            "2024-12-08 10:30:56,709 INFO     adam_epsilon:1e-08\n",
            "2024-12-08 10:30:56,709 INFO     gradient_accumulation_steps:1\n",
            "2024-12-08 10:30:56,709 INFO     max_grad_norm:1.0\n",
            "2024-12-08 10:30:56,709 INFO     dim_hidden:1024\n",
            "2024-12-08 10:30:56,709 INFO     alpha:0.0001\n",
            "2024-12-08 10:30:56,732 INFO     Create train_loader and val_loader.........\n",
            "#vocab of answer: 81629\n",
            "process concept\n",
            "100% 17754/17754 [00:00<00:00, 36739.23it/s]\n",
            "process attribute and relation\n",
            "100% 17754/17754 [00:03<00:00, 5491.43it/s] \n",
            "extract seen values\n",
            "100% 17754/17754 [00:11<00:00, 1555.73it/s]\n",
            "number of concepts: 794\n",
            "number of entities: 17754\n",
            "number of attribute keys: 846\n",
            "number of relations: 363\n",
            "2024-12-08 10:31:19,310 INFO     Create model.........\n",
            "added_tokens_num: 2\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "2024-12-08 10:31:23,501 INFO     BartForConditionalGeneration(\n",
            "  (model): BartModel(\n",
            "    (shared): BartScaledWordEmbedding(50267, 768, padding_idx=1)\n",
            "    (encoder): BartEncoder(\n",
            "      (embed_tokens): BartScaledWordEmbedding(50267, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x BartEncoderLayer(\n",
            "          (self_attn): BartSdpaAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): BartDecoder(\n",
            "      (embed_tokens): BartScaledWordEmbedding(50267, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x BartDecoderLayer(\n",
            "          (self_attn): BartSdpaAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartSdpaAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50267, bias=False)\n",
            ")\n",
            "2024-12-08 10:31:23,506 INFO     Checking...\n",
            "2024-12-08 10:31:23,506 INFO     ===================Dev==================\n",
            "100% 185/185 [02:32<00:00,  1.21it/s]\n",
            "11797it [00:00, 125922.73it/s]\n",
            "2024-12-08 10:34:06,677 INFO     acc: 0.05399677884207849\n",
            "100% 185/185 [04:19<00:00,  1.40s/it]\n",
            "11797it [00:00, 238210.85it/s]\n",
            "2024-12-08 11:50:41,114 INFO     acc: 0.05399677884207849\n",
            "2024-12-08 11:50:52,053 INFO     Saving model checkpoint to checkpoints/checkpoint-5899\n",
            "2024-12-08 11:50:58,005 INFO     Saving optimizer and scheduler states to checkpoints/checkpoint-5899\n",
            "2024-12-08 11:50:58,005 INFO     \n",
            "\n",
            "[Training] 733/5899 [==>...........................] - ETA: 1:03:05  loss: 0.0074 Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/KQAPro_Baselines/Bart_Program/train.py\", line 196, in <module>\n",
            "    main()\n",
            "  File \"/content/KQAPro_Baselines/Bart_Program/train.py\", line 192, in main\n",
            "    train(args)\n",
            "  File \"/content/KQAPro_Baselines/Bart_Program/train.py\", line 113, in train\n",
            "    outputs = model(**inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1642, in forward\n",
            "    outputs = self.model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1528, in forward\n",
            "    decoder_outputs = self.decoder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\", line 1313, in forward\n",
            "    encoder_attention_mask = _prepare_4d_attention_mask_for_sdpa(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py\", line 444, in _prepare_4d_attention_mask_for_sdpa\n",
            "    if not is_tracing and torch.all(mask == 1):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}