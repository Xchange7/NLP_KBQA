{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e11a5701-cea3-4c38-8f84-27f84aba242d",
      "metadata": {
        "id": "e11a5701-cea3-4c38-8f84-27f84aba242d"
      },
      "source": [
        "## KQAPro BART Integrated Pipeline - Bart_SPARQL Setup\n",
        "\n",
        "This Jupyter Notebook is designed to set up the pipeline for the [KQAPro Baselines - Bart_SPARQL](https://github.com/shijx12/KQAPro_Baselines/tree/master/Bart_SPARQL) project. It provides steps for downloading the necessary datasets, organizing files, and preparing the environment to run the Bart_SPARQL code.\n",
        "\n",
        "Ensure that all dependencies are installed and the required tools are available in your system before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd6584a",
      "metadata": {
        "id": "2fd6584a"
      },
      "source": [
        "> To Run it on **Colab**:\n",
        ">\n",
        "> 1. First, **upload** and open this jupyter **notebook** file  \n",
        ">\n",
        "> 2. Second, clone the related [github repository](https://github.com/Xchange7/NLP_KBQA) by executing the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "57ab1a4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ab1a4f",
        "outputId": "b780ee20-82b2-4c71-c675-1332b3612f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_KBQA'...\n",
            "remote: Enumerating objects: 451, done.\u001b[K\n",
            "remote: Counting objects: 100% (451/451), done.\u001b[K\n",
            "remote: Compressing objects: 100% (268/268), done.\u001b[K\n",
            "remote: Total 451 (delta 196), reused 420 (delta 169), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (451/451), 18.91 MiB | 13.76 MiB/s, done.\n",
            "Resolving deltas: 100% (196/196), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Xchange7/NLP_KBQA.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2b8b50",
      "metadata": {
        "id": "fd2b8b50"
      },
      "source": [
        "> 3. change the directory to `sp-based/`\n",
        ">\n",
        ">     Use `%cd` rather than `!cd` !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b553752",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b553752",
        "outputId": "4039bb8f-f50b-4e0f-a141-35749a15088c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_KBQA/sp-based\n"
          ]
        }
      ],
      "source": [
        "%cd NLP_KBQA/sp-based/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "uwIdx7jpK12U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwIdx7jpK12U",
        "outputId": "84d4d419-fef8-4f3d-ad14-df9be19c9a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_KBQA/sp-based\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8516955",
      "metadata": {
        "id": "d8516955"
      },
      "source": [
        "> 4. Now continue the following cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a",
      "metadata": {
        "id": "bd8e79dd-fcc0-4968-ad9f-b1171f7fd98a"
      },
      "source": [
        "### Download Datasets\n",
        "\n",
        "The following 4 jupyter cells will do the followings:\n",
        "\n",
        "- Download datasets `train.json`, `val.json` and `test.json` from [https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1](https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1)\n",
        "- Download datasets `kb.json` from [https://huggingface.co/datasets/drt/kqa_pro](https://huggingface.co/datasets/drt/kqa_pro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b805c03-47e8-46ff-9077-57309ad35b21",
        "outputId": "f8070cfd-52b8-4274-e012-1fe8c59d0308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-17 13:44:30--  https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\n",
            "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
            "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/cd563dca-ee25-45c8-bcf1-33cf605f421c/KQAPro.IID.zip [following]\n",
            "--2025-01-17 13:44:30--  https://cloud.tsinghua.edu.cn/seafhttp/files/cd563dca-ee25-45c8-bcf1-33cf605f421c/KQAPro.IID.zip\n",
            "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24786704 (24M) [application/zip]\n",
            "Saving to: ‘datasets.zip’\n",
            "\n",
            "datasets.zip        100%[===================>]  23.64M  28.6MB/s    in 0.8s    \n",
            "\n",
            "2025-01-17 13:44:31 (28.6 MB/s) - ‘datasets.zip’ saved [24786704/24786704]\n",
            "\n",
            "Archive:  datasets.zip\n",
            "   creating: datasets/KQAPro.IID/\n",
            "  inflating: datasets/KQAPro.IID/kb.json  \n",
            "  inflating: datasets/KQAPro.IID/README.md  \n",
            "  inflating: datasets/KQAPro.IID/train.json  \n",
            "  inflating: datasets/KQAPro.IID/test.json  \n",
            "  inflating: datasets/KQAPro.IID/val.json  \n"
          ]
        }
      ],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets.zip \"https://cloud.tsinghua.edu.cn/f/04ce81541e704a648b03/?dl=1\" \\\n",
        "&& unzip -o datasets.zip -d datasets \\\n",
        "&& mv datasets/KQAPro.IID/* datasets/ \\\n",
        "&& rm -r datasets/KQAPro.IID \\\n",
        "&& rm datasets.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beec3dab-52e2-4145-9795-964fbb3bff4a",
        "outputId": "63689702-3cbb-4bcd-9125-e083e24eafa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mBart_SPARQL\u001b[0m/                \u001b[01;34mdatasets\u001b[0m/      README.md        SPARQL_pipeline.ipynb\n",
            "Bart_SPARQL_pipeline.ipynb  evaluate.py    run_BlindGRU.sh  \u001b[01;34mtest_results\u001b[0m/\n",
            "\u001b[01;34mBlindGRU\u001b[0m/                   json2jsonl.py  \u001b[01;34mSPARQL\u001b[0m/          \u001b[01;34mutils\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e033209b-5085-4e91-94b8-944f05afe2ee",
        "outputId": "6c352a77-a620-4c72-a40d-0968e8da3302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-17 13:44:35--  https://huggingface.co/datasets/drt/kqa_pro/resolve/main/kb.json?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 3.169.137.111, 3.169.137.5, 3.169.137.119, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.169.137.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/c0/a4/c0a4536356b7a43fa2d5f4ca0859ea436a28848a2a32e920357a4480a00d4aa7/04da7408320c5cb7023c44372cce32846d56d369d8865d2e61a18c3956661a7c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27kb.json%3B+filename%3D%22kb.json%22%3B&response-content-type=application%2Fjson&Expires=1737380675&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzM4MDY3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jMC9hNC9jMGE0NTM2MzU2YjdhNDNmYTJkNWY0Y2EwODU5ZWE0MzZhMjg4NDhhMmEzMmU5MjAzNTdhNDQ4MGEwMGQ0YWE3LzA0ZGE3NDA4MzIwYzVjYjcwMjNjNDQzNzJjY2UzMjg0NmQ1NmQzNjlkODg2NWQyZTYxYTE4YzM5NTY2NjFhN2M%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Uy9zw74gAhqS3GcOOwRLH0b0ePzlhlzHhy2B-dv%7E0jGvrTNwNtj5zPnuZ8nHWXgVwZKLyUb%7EGqDJh9a-0ZqvQFUMIbwjsVJ5R5oZysB3jdHfaStLYumUsPGhc6JBuuL9NYy%7EPZSWEMlw8q1kSAh9aDyHJ-TswuCcvdqDE23vVrS4UmVfx8%7EFVzn3GfJAcgQJ4ecA9DQ0r%7EwopW2ebEHkTOjHuM4i9wDajgm9oh9w-KTfvD%7ENYCdXBVGfJyWKKA7urO6prf0z5a-%7EOAoz1FVz17-yUBmDNRHZdL9fJbjn6D4T6xFoCh47YNyD5EDJCp7dHG26DBeXDxKqOKNFae6MXg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-01-17 13:44:35--  https://cdn-lfs.hf.co/repos/c0/a4/c0a4536356b7a43fa2d5f4ca0859ea436a28848a2a32e920357a4480a00d4aa7/04da7408320c5cb7023c44372cce32846d56d369d8865d2e61a18c3956661a7c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27kb.json%3B+filename%3D%22kb.json%22%3B&response-content-type=application%2Fjson&Expires=1737380675&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzM4MDY3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jMC9hNC9jMGE0NTM2MzU2YjdhNDNmYTJkNWY0Y2EwODU5ZWE0MzZhMjg4NDhhMmEzMmU5MjAzNTdhNDQ4MGEwMGQ0YWE3LzA0ZGE3NDA4MzIwYzVjYjcwMjNjNDQzNzJjY2UzMjg0NmQ1NmQzNjlkODg2NWQyZTYxYTE4YzM5NTY2NjFhN2M%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Uy9zw74gAhqS3GcOOwRLH0b0ePzlhlzHhy2B-dv%7E0jGvrTNwNtj5zPnuZ8nHWXgVwZKLyUb%7EGqDJh9a-0ZqvQFUMIbwjsVJ5R5oZysB3jdHfaStLYumUsPGhc6JBuuL9NYy%7EPZSWEMlw8q1kSAh9aDyHJ-TswuCcvdqDE23vVrS4UmVfx8%7EFVzn3GfJAcgQJ4ecA9DQ0r%7EwopW2ebEHkTOjHuM4i9wDajgm9oh9w-KTfvD%7ENYCdXBVGfJyWKKA7urO6prf0z5a-%7EOAoz1FVz17-yUBmDNRHZdL9fJbjn6D4T6xFoCh47YNyD5EDJCp7dHG26DBeXDxKqOKNFae6MXg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.169.121.124, 3.169.121.44, 3.169.121.27, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.169.121.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79341787 (76M) [application/json]\n",
            "Saving to: ‘datasets/kb.json’\n",
            "\n",
            "datasets/kb.json    100%[===================>]  75.67M  94.5MB/s    in 0.8s    \n",
            "\n",
            "2025-01-17 13:44:36 (94.5 MB/s) - ‘datasets/kb.json’ saved [79341787/79341787]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Simply run it\n",
        "\n",
        "!wget -O datasets/kb.json \"https://huggingface.co/datasets/drt/kqa_pro/resolve/main/kb.json?download=true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eb65f55-aa46-41e8-ac9d-779fee897e57",
        "outputId": "3aa142b6-322e-4f83-ed08-792077c665e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kb.json  README.md  test.json  train.json  val.json\n"
          ]
        }
      ],
      "source": [
        "%ls ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5696ed62",
      "metadata": {
        "id": "5696ed62"
      },
      "source": [
        "### Modify the datasets\n",
        "\n",
        "- Current structures of `train.json`, `val.json`:\n",
        "  ```json\n",
        "  {\n",
        "    \"question\": \"\",   // !!! input of the model\n",
        "    \"choices\": [],  // ignore this field\n",
        "    \"program\": [],  // ignore this field\n",
        "    \"sparql\": \"\",   // !!! output of the model\n",
        "    \"answer\": \"\"  // ignore this field\n",
        "  }\n",
        "  ```\n",
        "\n",
        "- Current structure of `test.json`:\n",
        "  ```json\n",
        "  {\n",
        "    \"question\": \"\",   // !!! input of the model\n",
        "    \"answer\": \"\"  // ignore this field\n",
        "  }  // PROBLEM: no `sparql` field\n",
        "  ```\n",
        "\n",
        "- Current `test.json` file has no `sparql` field, so we split the `val.json` into two parts, taking the last **5000** pieces of samples as new test set, and others as evaluation set.\n",
        "- At the same time, we also restructure the json format in all `train.json`, `val.json`, `test.json` files with proper **indentation**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "681a2d78",
      "metadata": {
        "id": "681a2d78"
      },
      "outputs": [],
      "source": [
        "!rm ./datasets/test.json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c70d960d",
      "metadata": {
        "id": "c70d960d"
      },
      "source": [
        "Currently, all data are stored in **a single line** in each file, which is not human-readable. We will reformat the data to make it more readable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "534a5ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "534a5ba5",
        "outputId": "6dbf7a37-edb4-4813-a9a4-3714a053d12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0 ./datasets/kb.json\n",
            "        0 ./datasets/train.json\n",
            "        0 ./datasets/val.json\n",
            "        0 total\n"
          ]
        }
      ],
      "source": [
        "!wc -l ./datasets/*.json  # calculate the number of lines in each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b44f9c4d",
      "metadata": {
        "id": "b44f9c4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0138973a-1c43-453b-d002-5a6493bc9435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully split `val.json` into `val.json` and `test.json`, and restructured all files with indentation.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "with open('./datasets/val.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "if len(data) != 11797:  # original number of samples in `val.json`\n",
        "    # the file has been restructured with proper indentation\n",
        "    raise Exception('The file `val.json` has been split into `val.json` and `test.json` already!\\nNo need to run this script again.')\n",
        "\n",
        "# fetch the last 5000 samples as test data\n",
        "test_data = data[-5000:]\n",
        "remaining_data = data[:-5000]\n",
        "\n",
        "with open('./datasets/test.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(test_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "with open('./datasets/val.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(remaining_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# at the same time, restructure `train.json` with proper indentation\n",
        "with open('./datasets/train.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "with open('./datasets/train.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print('Successfully split `val.json` into `val.json` and `test.json`, and restructured all files with indentation.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ec89a24a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec89a24a",
        "outputId": "0118f0dd-d67f-4be1-9aba-b89086288702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0 ./datasets/kb.json\n",
            "   296868 ./datasets/test.json\n",
            "  5580649 ./datasets/train.json\n",
            "   404696 ./datasets/val.json\n",
            "  6282213 total\n"
          ]
        }
      ],
      "source": [
        "!wc -l ./datasets/*.json  # calculate the number of lines in each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f277af7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f277af7c",
        "outputId": "9bcbcd07-040d-4189-8e0d-4d33e0bebece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted datasets/train.json to datasets/train.jsonl\n",
            "Successfully converted datasets/test.json to datasets/test.jsonl\n",
            "Successfully converted datasets/val.json to datasets/val.jsonl\n"
          ]
        }
      ],
      "source": [
        "# OPTIONAL: convert `train.json`, `val.json`, and `test.json` to `jsonl` format\n",
        "\n",
        "!python json2jsonl.py --mode default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1cba9303",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cba9303",
        "outputId": "e8247565-92f0-4daa-db45-64bb4beb6287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    5000 ./datasets/test.jsonl\n",
            "   94376 ./datasets/train.jsonl\n",
            "    6797 ./datasets/val.jsonl\n",
            "  106173 total\n"
          ]
        }
      ],
      "source": [
        "!wc -l ./datasets/*.jsonl  # calculate the number of lines in each file, which represents the number of samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d223c74d-d46d-4799-84f9-202a070f3816",
      "metadata": {
        "id": "d223c74d-d46d-4799-84f9-202a070f3816"
      },
      "source": [
        "### Configure rdflib package\n",
        "\n",
        "Follow the instructions in [https://github.com/shijx12/KQAPro_Baselines/tree/master/Bart_SPARQL#requirements](https://github.com/shijx12/KQAPro_Baselines/tree/master/Bart_SPARQL#requirements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f410d6a3-bb22-4171-8b60-60c78b2d9a34",
        "outputId": "5076e36d-6ff9-4bc5-84b3-5633e1c9710f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from rdflib) (3.2.1)\n",
            "Downloading rdflib-7.1.2-py3-none-any.whl (567 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.0/567.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdflib\n",
            "Successfully installed rdflib-7.1.2\n"
          ]
        }
      ],
      "source": [
        "%pip install rdflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3efa088f-a8c7-4a81-92eb-e25a4bdd5d3a",
        "outputId": "367b81d5-9981-4062-fcd2-e13bf74dff99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_dir: /usr/local/lib/python3.11/dist-packages/rdflib\n",
            "\n",
            "There are 2 files to change in total.\n",
            "File1: /usr/local/lib/python3.11/dist-packages/rdflib/plugins/sparql/parser.py\n",
            "File2: /usr/local/lib/python3.11/dist-packages/rdflib/plugins/serializers/turtle.py\n",
            "\n",
            "First, edit file1, replace the line with codes:\n",
            "`if i + 1 < l and (not isinstance(terms[i + 1], str) or terms[i + 1] not in \".,;\"):`\n",
            "which is just below the line `# is this bnode the subject of more triplets?`\n",
            "\n",
            "Second, edit file2, replace `use_plain=True` with `use_plain=False`\n",
            "\n",
            "For more detailed information, check https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements\n"
          ]
        }
      ],
      "source": [
        "import rdflib\n",
        "import os\n",
        "\n",
        "\"\"\" Follow the instructions of the output below: \"\"\"\n",
        "\n",
        "base_dir = os.path.dirname(rdflib.__file__)\n",
        "print(f\"base_dir: {base_dir}\")\n",
        "\n",
        "file1 = os.path.join(base_dir, \"plugins/sparql/parser.py\")\n",
        "file2 = os.path.join(base_dir, \"plugins/serializers/turtle.py\")\n",
        "\n",
        "\"\"\"What you need TODO:\"\"\"\n",
        "print(\"\\nThere are 2 files to change in total.\")\n",
        "print(f\"File1: {file1}\")\n",
        "print(f\"File2: {file2}\")\n",
        "\n",
        "print(f\"\"\"\n",
        "First, edit file1, replace the line with codes:\n",
        "`if i + 1 < l and (not isinstance(terms[i + 1], str) or terms[i + 1] not in \".,;\"):`\n",
        "which is just below the line `# is this bnode the subject of more triplets?`\n",
        "\"\"\", end=\"\")\n",
        "\n",
        "print(f\"\"\"\n",
        "Second, edit file2, replace `use_plain=True` with `use_plain=False`\n",
        "\"\"\")\n",
        "\n",
        "print(\"For more detailed information, check https://github.com/shijx12/KQAPro_Baselines/tree/master/SPARQL#requirements\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wHZc03euLHNH",
      "metadata": {
        "id": "wHZc03euLHNH"
      },
      "source": [
        "Now edit file1 and file2.\n",
        "\n",
        "> For Colab users, the file paths could be:  \n",
        ">\n",
        "> File1: /usr/local/lib/python3.11/dist-packages/rdflib/plugins/sparql/parser.py  (line: 84)\n",
        ">\n",
        "> File2: /usr/local/lib/python3.11/dist-packages/rdflib/plugins/serializers/turtle.py  (line: 356)\n",
        ">\n",
        "> Simply click the file links to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ad52a04-9360-4203-847f-b5221e1eabfc",
      "metadata": {
        "id": "5ad52a04-9360-4203-847f-b5221e1eabfc"
      },
      "source": [
        "### Configure SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab050a27-3804-4816-b2f6-c731d3e64cce",
        "outputId": "2851bd0b-80ca-410c-b7fc-634bad17ee16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SPARQLWrapper==1.8.4\n",
            "  Downloading SPARQLWrapper-1.8.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: rdflib>=4.0 in /usr/local/lib/python3.11/dist-packages (from SPARQLWrapper==1.8.4) (7.1.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from rdflib>=4.0->SPARQLWrapper==1.8.4) (3.2.1)\n",
            "Downloading SPARQLWrapper-1.8.4-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-1.8.4\n"
          ]
        }
      ],
      "source": [
        "%pip install SPARQLWrapper==1.8.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d518e511-c41b-4042-80a9-44967f5e515b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d518e511-c41b-4042-80a9-44967f5e515b",
        "outputId": "832a9dcd-8a62-46df-ba9c-2b48fa8540e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: keepalive\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip show keepalive  # Make sure `keepalive` NOT installed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9",
      "metadata": {
        "id": "2501d07c-85b3-4d27-b37a-1801ef9606f9"
      },
      "source": [
        "### Virtuoso Configuration\n",
        "\n",
        "> *Needed for validation and evaluation (Executing SPARQL query to local Virtuoso database)*\n",
        "\n",
        "- The virtuoso backend will start up a web service, we can import our kb into it and then execute SPARQL queries by network requests.\n",
        "- **Purpose of Virtuoso**: The primary purpose of this configuration is to install and set up the Virtuoso backend service on an Ubuntu system, enabling the import of a **knowledge base (KB)** and facilitating access and operations on the data through the **SPARQL query interface**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd",
      "metadata": {
        "id": "2e7d923a-41e8-40ac-b9bf-282b92aee9fd"
      },
      "source": [
        "Follow the steps in [https://github.com/shijx12/KQAPro_Baselines/tree/master/Bart_SPARQL#how-to-install-virtuoso-backend](https://github.com/shijx12/KQAPro_Baselines/tree/master/Bart_SPARQL#how-to-install-virtuoso-backend)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eaff19f",
      "metadata": {
        "id": "8eaff19f"
      },
      "source": [
        "### Loguru Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cb20ca86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb20ca86",
        "outputId": "61c3e997-e1e4-4ce9-8b27-ff066862809f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n"
          ]
        }
      ],
      "source": [
        "%pip install loguru"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6b7ba8",
      "metadata": {
        "id": "ca6b7ba8"
      },
      "source": [
        "### Download the pre-trained BART model\n",
        "\n",
        "1. The pretrained **Bart-base checkpoint** without finetuning can be downloaded here [bart-base](https://cloud.tsinghua.edu.cn/f/3b59ec6c43034cfc8841/?dl=1)\n",
        "2. The checkpoint for **finetuned Bart_SPARQL** can be downloaded here [finetuned](https://cloud.tsinghua.edu.cn/f/1b9746dcd96b4fca870d/?dl=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a3e79641",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3e79641",
        "outputId": "90bc7bb8-cf63-4ad9-b772-cf5bd4f01b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-17 13:45:15--  https://cloud.tsinghua.edu.cn/f/3b59ec6c43034cfc8841/?dl=1\n",
            "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 101.6.15.69, 2402:f000:1:402:101:6:15:69\n",
            "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|101.6.15.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/af747d3c-052f-4157-8b87-5bc74b7cdbaf/bart-base.zip [following]\n",
            "--2025-01-17 13:45:15--  https://cloud.tsinghua.edu.cn/seafhttp/files/af747d3c-052f-4157-8b87-5bc74b7cdbaf/bart-base.zip\n",
            "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 329582587 (314M) [application/zip]\n",
            "Saving to: ‘bart_base_model.zip’\n",
            "\n",
            "bart_base_model.zip 100%[===================>] 314.31M  55.8MB/s    in 5.9s    \n",
            "\n",
            "2025-01-17 13:45:21 (53.1 MB/s) - ‘bart_base_model.zip’ saved [329582587/329582587]\n",
            "\n",
            "Archive:  bart_base_model.zip\n",
            "   creating: bart_base_model/bart-base/\n",
            "  inflating: bart_base_model/bart-base/vocab.url.json  \n",
            "  inflating: bart_base_model/bart-base/config.url.json  \n",
            "  inflating: bart_base_model/bart-base/config.json  \n",
            "  inflating: bart_base_model/bart-base/merges.txt  \n",
            "  inflating: bart_base_model/bart-base/merges.url.json  \n",
            "  inflating: bart_base_model/bart-base/pytorch_model.url.bin  \n",
            "  inflating: bart_base_model/bart-base/pytorch_model.bin  \n",
            "  inflating: bart_base_model/bart-base/vocab.json  \n"
          ]
        }
      ],
      "source": [
        "!wget -O bart_base_model.zip \"https://cloud.tsinghua.edu.cn/f/3b59ec6c43034cfc8841/?dl=1\" \\\n",
        "&& unzip -o bart_base_model.zip -d bart_base_model \\\n",
        "&& rm bart_base_model.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b96db1cf-2994-4b60-a454-5ae07852351a",
      "metadata": {
        "id": "b96db1cf-2994-4b60-a454-5ae07852351a"
      },
      "source": [
        "### Preprocess the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6ae20098-be27-484c-b327-6d189b5a199c",
      "metadata": {
        "id": "6ae20098-be27-484c-b327-6d189b5a199c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cc5de7-f6af-48e8-bd96-4337c791d4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
      "metadata": {
        "id": "7a62e93b-707c-44fc-a173-17209ed9eec9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf92f5a-98a2-45ce-f69b-d810fbecc835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-17 13:45:56.746941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-17 13:45:56.823398: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-17 13:45:56.859277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-17 13:45:56.915550: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-17 13:46:00.480680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "GroupViT models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version.Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "Build kb vocabulary\n",
            "Load questions\n",
            "Dump vocab to bart_processed_data/vocab.json\n",
            "answer_token_to_idx:79329\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 1.70MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 1.29MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 2.56MB/s]\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/merges.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/tokenizer.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "config.json: 100% 1.72k/1.72k [00:00<00:00, 10.5MB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"facebook/bart-base\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Encode train set\n",
            "100% 94376/94376 [00:00<00:00, 1373077.04it/s]\n",
            "dict_keys(['input_ids', 'attention_mask'])\n",
            "[0, 32251, 1139, 34, 10, 3842, 2688, 9, 204, 45121, 406, 34916, 3416, 1360, 8, 34, 41, 8192, 7961, 5135, 9, 6178, 398, 35534, 116, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "<s>Which town has a TOID of 4000000074573917 and has an OS grid reference of SP8778?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "<s>SELECT DISTINCT ?qpv WHERE { ?e <pred:instance_of> ?c . ?c <pred:name> \"visual artwork\" . ?e <official_website> ?pv_1 . ?pv_1 <pred:value> \"http://www.thesiege.com/\" . ?e <publication_date> ?pv . ?pv <pred:date> \"1999-01-21\"^^xsd:date . [ <pred:fact_h> ?e ; <pred:fact_r> <publication_date> ; <pred:fact_t> ?pv ] <place_of_publication> ?qpv .  }</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "304\n",
            "100% 94376/94376 [00:00<00:00, 253056.52it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "shape of input_ids of questions, attention_mask of questions, input_ids of sparqls, choices and answers:\n",
            "(94376, 304)\n",
            "(94376, 304)\n",
            "(94376, 304)\n",
            "(94376, 10)\n",
            "(94376,)\n",
            "Encode val set\n",
            "100% 6797/6797 [00:00<00:00, 935324.29it/s]\n",
            "dict_keys(['input_ids', 'attention_mask'])\n",
            "[0, 12375, 21, 5, 4588, 1924, 77, 3801, 4, 3635, 8538, 300, 5, 3536, 3683, 13, 2700, 8123, 6, 27738, 196, 14828, 5785, 116, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "<s>Who was the prize winner when Mrs. Miniver got the Academy Award for Best Writing, Adapted Screenplay?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "<s>SELECT DISTINCT ?qpv WHERE { ?e <pred:instance_of> ?c . ?c <pred:name> \"television station\" . ?e_1 <original_network> ?e . ?e_1 <pred:name> \"Aladdin\" . ?e_1 <genre> ?e_2 . ?e_2 <pred:name> \"television comedy\" .  ?e <official_website> ?pv . ?pv <pred:value> \"http://www.disneychannel.com/\" . [ <pred:fact_h> ?e ; <pred:fact_r> <official_website> ; <pred:fact_t> ?pv ] <language_of_work_or_name> ?qpv .  }</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "288\n",
            "100% 6797/6797 [00:00<00:00, 157444.78it/s]\n",
            "shape of input_ids of questions, attention_mask of questions, input_ids of sparqls, choices and answers:\n",
            "(6797, 288)\n",
            "(6797, 288)\n",
            "(6797, 288)\n",
            "(6797, 10)\n",
            "(6797,)\n",
            "Encode test set\n",
            "100% 5000/5000 [00:00<00:00, 1616675.92it/s]\n",
            "dict_keys(['input_ids', 'attention_mask'])\n",
            "[0, 6209, 10433, 16154, 5, 599, 40952, 9, 5, 621, 19, 3703, 17640, 47489, 16273, 2663, 501, 1898, 9465, 3570, 116, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "<s>Is Socceroos the Twitter username of the person with ISNI 0000 0001 1445 0107?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "<s>How is Luzerne County related to Wilkes-Barre?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "108\n",
            "100% 5000/5000 [00:00<00:00, 274607.76it/s]\n",
            "shape of input_ids of questions, attention_mask of questions, input_ids of sparqls, choices and answers:\n",
            "(5000, 108)\n",
            "(5000, 108)\n",
            "(0,)\n",
            "(5000, 10)\n",
            "(0,)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m Bart_SPARQL.preprocess --input_dir datasets --output_dir bart_processed_data \\\n",
        "    --model_name_or_path facebook/bart-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
      "metadata": {
        "id": "51d143a9-8f7b-49b2-b68c-910775510b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a38992-b1d8-4017-b072-1c58a609b802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bart_processed_data:\n",
            "test.pt  train.pt  val.pt  vocab.json\n",
            "\n",
            "datasets:\n",
            "kb.json  README.md  test.json  test.jsonl  train.json  train.jsonl  val.json  val.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls datasets bart_processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a",
      "metadata": {
        "id": "e83026cf-86d4-4e82-9e2a-85c1cf8fde0a"
      },
      "outputs": [],
      "source": [
        "!cp ./datasets/kb.json bart_processed_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive (Colab)"
      ],
      "metadata": {
        "id": "UXrYJ2gNhabS"
      },
      "id": "UXrYJ2gNhabS"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/NLP_KBQA/sp-based/bart_checkpoints')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE0KQX_-hhDA",
        "outputId": "2beea295-2beb-4438-996c-95ba7832ae15"
      },
      "id": "NE0KQX_-hhDA",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/NLP_KBQA/sp-based/bart_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1511c61b-a00a-4264-afce-a9b947171e9a",
      "metadata": {
        "id": "1511c61b-a00a-4264-afce-a9b947171e9a"
      },
      "source": [
        "### Train\n",
        "\n",
        "**BUG here!!!**:  \n",
        "\n",
        "There is a bug when the command below is executed with GPU, which can be fixed by editing the file:   \n",
        "`....../dist-packages/torch/nn/utils/rnn.py`  \n",
        "In Colab, the file path is:  \n",
        "`/usr/local/lib/python3.11/dist-packages/torch/nn/utils/rnn.py: line 338`\n",
        "\n",
        "Add `lengths = lengths.cpu()` before the line `data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c109e198-cf8d-434c-9f43-a618f3279326",
      "metadata": {
        "id": "c109e198-cf8d-434c-9f43-a618f3279326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbe2917-0dc4-4cdb-c788-7c88e3d17c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-17 14:00:41.781474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-17 14:00:41.805851: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-17 14:00:41.813137: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-17 14:00:41.831230: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-17 14:00:43.521287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2025-01-17 14:00:44.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1minput_dir: bart_processed_data\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1moutput_dir: bart_checkpoints/MyDrive/sp-plms/\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1msave_dir: bart_checkpoints/MyDrive/sp-plms/\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mmodel_name_or_path: facebook/bart-base\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mckpt: None\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mweight_decay: 1e-05\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mbatch_size: 8\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mseed: 666\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mlearning_rate: 3e-05\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mnum_train_epochs: 30\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1msave_steps: 448\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mlogger_steps: 448\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mwarmup_proportion: 0.1\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1madam_epsilon: 1e-08\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mgradient_accumulation_steps: 1\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mmax_grad_norm: 1.0\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mdim_hidden: 1024\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1malpha: 0.0001\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mUsing device: cpu\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:44.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mCreate train_loader and val_loader.........\u001b[0m\n",
            "#vocab of answer: 79329\n",
            "\u001b[32m2025-01-17 14:00:45.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mCreate model.........\u001b[0m\n",
            "model.safetensors: 100% 558M/558M [00:06<00:00, 86.1MB/s]\n",
            "\u001b[32m2025-01-17 14:00:55.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mBartForConditionalGeneration(\n",
            "  (model): BartModel(\n",
            "    (shared): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
            "    (encoder): BartEncoder(\n",
            "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x BartEncoderLayer(\n",
            "          (self_attn): BartSdpaAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): BartDecoder(\n",
            "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x BartDecoderLayer(\n",
            "          (self_attn): BartSdpaAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartSdpaAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:55.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mChecking...\u001b[0m\n",
            "\u001b[32m2025-01-17 14:00:55.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1m===================Dev==================\u001b[0m\n",
            "[Training] 11/11797 [..............................] - ETA: 148:56:10  loss: 8.1450 "
          ]
        }
      ],
      "source": [
        "# without GPU\n",
        "!python3 -m Bart_SPARQL.train --input_dir bart_processed_data --output_dir bart_checkpoints/MyDrive/sp-plms/ --model_name_or_path facebook/bart-base --save_dir bart_checkpoints/MyDrive/sp-plms/\n",
        "\n",
        "# with GPU\n",
        "# Run on Colab: --virtuoso_enabled False, there is no Virtuoso on Colab, no validating when training\n",
        "# !CUDA_VISIBLE_DEVICES=0 python -m Bart_SPARQL.train --input_dir bart_processed_data --output_dir bart_checkpoints/MyDrive/sp-plms --model_name_or_path facebook/bart-base --save_dir bart_checkpoints/MyDrive/sp-plms/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8df0ce",
      "metadata": {
        "id": "0c8df0ce"
      },
      "source": [
        "### Test\n",
        "\n",
        "On Colab: It's unable to run the test command without configuration of Virtuoso Service"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c922a11f",
      "metadata": {
        "id": "c922a11f"
      },
      "source": [
        "**'single' mode**: processes one model file only. `--save_dir` must be a path to a single .pt file\n",
        "\n",
        "**'multiple' mode**: processes all model files in a directory. `--save_dir` must be a path to a directory containing multiple .pt files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4161ab87-26ba-4a71-863d-bfab745daea7",
      "metadata": {
        "id": "4161ab87-26ba-4a71-863d-bfab745daea7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "'single' mode: replace 'checkpoints/model_epoch0.pt' with your own model path\n",
        "\"\"\"\n",
        "\n",
        "# without GPU\n",
        "!python -m SPARQL.test --input_dir processed_data --save_dir checkpoints/model_epoch0.pt --mode single --results_dir test_results\n",
        "\n",
        "# with GPU\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.test --input_dir processed_data --save_dir checkpoints/model_epoch0.pt --mode single --results_dir test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UQIsX1vfgLQL",
      "metadata": {
        "id": "UQIsX1vfgLQL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "'multiple' mode: replace 'checkpoints' with your own directory path of all .pt files\n",
        "\"\"\"\n",
        "\n",
        "# without GPU\n",
        "!python3 -m SPARQL.test --input_dir processed_data --save_dir checkpoints_from_colab --mode multiple --results_dir test_results\n",
        "\n",
        "# with GPU\n",
        "!CUDA_VISIBLE_DEVICES=0 python -m SPARQL.test --input_dir processed_data --save_dir checkpoints --mode multiple --results_dir test_results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}